# 强化学习

## 学习路径

### 1. **掌握基础 Python 语法**

你应该确保自己已经掌握了以下 Python 基础内容：

- **数据类型与控制结构**：`int`, `float`, `str`, `list`, `tuple`, `dict`, `set`，条件语句（`if`）、循环语句（`for`, `while`）、函数定义与调用、异常处理等。
- **面向对象编程（OOP）**：理解类（`class`）和对象（`object`）的概念，掌握如何定义类和实例化对象。
- **模块与包的使用**：如何导入 Python 的标准库（如 `random`, `os`, `datetime` 等），以及如何使用第三方库。
- **列表与字典的操作**：掌握如何在 Python 中操作和处理列表、字典等容器类型。

如果你还不熟悉这些基础内容，可以参考以下学习资源：

- 《Python 编程：从入门到实践》
- 官方 Python 文档（[Python 官方教程](https://docs.python.org/3/tutorial/)）

### 2. **学习 NumPy 和 PyTorch 基础**

DQN 代码中的深度学习部分主要使用了 **PyTorch**，而训练神经网络的基础是 **NumPy**。所以你需要学习如何使用这两个库。

#### **NumPy 基础**

NumPy 是 Python 中处理数组、矩阵等多维数据的基本库，许多深度学习框架都基于它。你需要理解以下内容：

- 创建和操作多维数组（`ndarray`）
- 数学运算：矩阵运算、广播（broadcasting）等
- 数组的切片、索引、重塑等操作
- 随机数生成（如生成随机数组）

可以参考以下学习资源：

- NumPy 官方文档
- 《Python 科学计算：NumPy 和 SciPy》

#### **PyTorch 基础**

PyTorch 是一个广泛使用的深度学习框架，支持神经网络的构建与训练。你需要掌握以下内容：

- **张量（Tensor）**：PyTorch 中的核心数据结构。张量类似于 NumPy 数组，但可以在 GPU 上运行。
- **神经网络模块（`torch.nn`）**：如何构建神经网络，如何定义层（如 `Linear`, `ReLU`）以及如何进行前向传播。
- **自动求导（Autograd）**：如何计算梯度以及使用反向传播更新权重。
- **优化器（`torch.optim`）**：如何使用不同的优化器（如 Adam、SGD）来更新神经网络的权重。

可以参考以下学习资源：

- PyTorch 官方文档
- Deep Learning with PyTorch: A 60-minute Blitz
- 《Deep Learning with PyTorch》

### 3. **学习强化学习基础**

DQN 是强化学习中的一种算法，因此你需要理解强化学习的基本概念。主要包括以下内容：

- **强化学习的基本要素**：代理（Agent）、环境（Environment）、状态（State）、动作（Action）、奖励（Reward）等。
- **Q 学习**：强化学习中常见的算法，学习 Q 函数来估计状态-动作对的价值。
- **探索与利用**：`epsilon-greedy` 策略，权衡探索新动作和利用已知最优动作之间的关系。
- **经验回放池**：经验回放池用于存储过去的经验，并从中随机采样进行训练，以打破数据的相关性。

可以参考以下学习资源：

- David Silver's Reinforcement Learning Course
- 《Reinforcement Learning: An Introduction》 by Sutton and Barto（这是一本强化学习的经典教材）

### 4. **逐步构建深度Q网络（DQN）**

当你掌握了基础的 Python 编程、PyTorch 和强化学习之后，你就可以开始实现自己的 DQN 代码了。以下是一步步的指导：

#### **(1) 构建神经网络（`Net` 类）**

首先，定义一个简单的前馈神经网络，用于预测每个动作的 Q 值。你可以使用 PyTorch 的 `nn.Linear` 来定义全连接层，并使用 ReLU 激活函数来引入非线性。

#### **(2) 定义 DQN 类**

DQN 需要两个神经网络：一个是 **评估网络（eval_net）**，用来选择动作并计算 Q 值；另一个是 **目标网络（target_net）**，用来计算目标 Q 值。你可以在 `DQN` 类中使用 `torch.optim.Adam` 来定义优化器，使用 `nn.MSELoss` 来计算损失。

#### **(3) 动作选择（`take_action` 方法）**

根据 epsilon-greedy 策略，你可以在训练时随机选择动作或选择最大 Q 值对应的动作。在测试时，只需选择 Q 值最大的动作。

#### **(4) 网络更新（`update` 方法）**

每次从经验回放池中采样一批数据，使用贝尔曼方程来更新 Q 值。计算损失并通过反向传播更新网络参数。

#### **(5) 经验回放池（Replay Buffer）**

经验回放池用于存储智能体的经验，并提供随机采样的功能。你可以创建一个简单的队列（`collections.deque`），存储状态、动作、奖励和下一个状态的元组。

### 5. **调试与优化**

实现了 DQN 的核心部分后，你需要进行大量的调试和优化：

- **调试训练过程**：在训练过程中，确保网络能够正常收敛，Q 值逐渐逼近目标 Q 值。
- **调整超参数**：如学习率、折扣因子（`gamma`）、epsilon-greedy 策略中的 epsilon 值等，尝试不同的组合以获得最佳的训练效果。

### 6. **进一步学习**

当你熟悉了基础的 DQN 实现后，你可以进一步学习更复杂的强化学习算法，如 Double DQN、Dueling DQN、A3C、PPO 等。

## 第一次学习

### 定义类

使用`class`关键字来定义一个类。类名的首字母通常大写，并采用驼峰命名法（CamelCase）。以下是一个简单的类定义示例：

```python
class MyClass:
    pass  # 使用pass占位，表示这是一个空类
```

### 类属性和方法

#### 类属性

类属性是在类级别定义的变量，它们被类的所有实例共享。

```python
class MyClass:
    class_attribute = "I am a class attribute"
 
# 访问类属性
print(MyClass.class_attribute)  # 输出: I am a class attribute
```

#### 实例属性

实例属性是在类的实例（对象）上定义的变量。它们通常通过初始化方法（`__init__`）来设置。

```python
class MyClass:
    def __init__(self, instance_attribute):
        self.instance_attribute = instance_attribute
 
# 创建类的实例
obj = MyClass("I am an instance attribute")
print(obj.instance_attribute)  # 输出: I am an instance attribute
```

#### 方法

方法是在类内部定义的函数。第一个参数通常是`self`，它代表类的实例本身。

```python
class MyClass:
    def my_method(self):
        print("This is a method")
 
# 创建类的实例并调用方法
obj = MyClass()
obj.my_method()  # 输出: This is a method
```

### 构造函数和析构函数

#### 构造函数

构造函数是在创建类的实例时自动调用的方法。在Python中，通常使用`__init__`作为构造函数。

```python
class MyClass:
    def __init__(self, value):
        self.value = value
 
obj = MyClass(10)
print(obj.value)  # 输出: 10
```

#### 析构函数

析构函数是在类的实例被销毁时自动调用的方法。在Python中，通常使用`__del__`作为析构函数。

```python
class MyClass:
    def __del__(self):
        print("Object is being destroyed")
 
# 创建类的实例，在程序结束时会自动调用析构函数
obj = MyClass()
# 注意：析构函数的输出可能在程序结束时才会看到，取决于垃圾回收的时机
```

### 继承

继承是面向对象编程的一个重要特性，它允许一个类（子类）继承另一个类（父类）的属性和方法。

```python
class Parent:
    def __init__(self, name):
        self.name = name
 
    def greet(self):
        print(f"Hello, my name is {self.name}")
 
class Child(Parent):
    def __init__(self, name, age):
        super().__init__(name)  # 调用父类的构造函数
        self.age = age
 
    def greet(self):
        super().greet()  # 调用父类的方法
        print(f"And I am {self.age} years old")
 
# 创建子类的实例
child = Child("Alice", 12)
child.greet()
# 输出:
# Hello, my name is Alice
# And I am 12 years old
```

### 特殊方法（魔术方法）

Python中有一些特殊方法，它们以双下划线（`__`）开头和结尾，用于实现特定的功能，如字符串表示、数值运算等。

```python
class MyClass:
    def __init__(self, value):
        self.value = value
 
    def __str__(self):
        return f"MyClass with value {self.value}"
 
    def __add__(self, other):
        return MyClass(self.value + other.value)
 
obj1 = MyClass(10)
obj2 = MyClass(20)
print(obj1)  # 输出: MyClass with value 10
print(obj1 + obj2)  # 输出: MyClass with value 30
```

### 静态方法和类方法

#### 静态方法

静态方法不依赖于类的实例，它们可以通过类直接调用，也可以通过实例调用。使用`@staticmethod`装饰器来定义静态方法。

```python
class MyClass:
    @staticmethod
    def static_method():
        print("This is a static method")
 
MyClass.static_method()  # 输出: This is a static method
obj = MyClass()
obj.static_method()  # 输出: This is a static method
```

#### 类方法

类方法依赖于类本身，但不需要实例。它们接收类作为第一个参数（通常是`cls`），而不是实例（`self`）。使用`@classmethod`装饰器来定义类方法。

```python
class MyClass:
    class_variable = "I am a class variable"
 
    @classmethod
    def class_method(cls):
        print(cls.class_variable)
 
MyClass.class_method()  # 输出: I am a class variable
obj = MyClass()
obj.class_method()  # 输出: I am a class variable
```

## 第二次学习

### 创建和操作多维数组（`ndarray`）

**`ndarray`** 是 NumPy 中的核心数据结构，它是一个多维数组（可以是 1D、2D、3D 等），支持高效的数学运算。

创建 `ndarray`

可以通过多种方式创建 `ndarray`：

- **从列表或元组创建：**

  ```python
  import numpy as np
  arr=np.array([1,2,3,4])#一维数组
  print(arr)
  ```

- **创建多维数组：**

  ```python
  arr_2d=np.array([[1,2],[3,4],[5,6]])#二维数组
  print(arr_2d)
  ```

- **使用 `zeros` 和 `ones`：** 创建全为 0 或 1 的数组：

  ```python
  zeros_arr = np.zeros((3,3))#3*3的零矩阵
  ones_arr = np.ones((2,4))#2*4的一矩阵
  ```

- **使用 `arange` 和 `linspace`：** `arange` 创建一个范围内的等差数列，`linspace` 在指定区间内生成均匀分布的点。

  ```python
  arr=np.arange(0,10,2)#[0,2,4,6,8]
  arr_linspace = np.linspace(0,1,5)#[0,0.25,0.5,0.75,1]
  ```

### **数学运算：矩阵运算、广播（broadcasting）等**

NumPy 支持广泛的数学运算，比如矩阵运算、向量化运算（通过广播）等，计算非常高效。

#### 矩阵运算

- **加法、减法、乘法、除法：**

  ```python
  arr1 = np.array([1,2,3])
  arr2 = np.array([4,5,6])
  
  sum_arr = arr1 + arr2
  diff_arr = arr1 - arr2
  prod_arr = arrr1 * arr2
  div_arr = arr1 / arr2
  ```

- **矩阵乘法：**

  ```python
  arr1 = np.array([[1,2],[3,4]])
  arr2 = np.array([[5,6],[7,8]])
  matrix_prod = np.dot(arr1,arr2)
  ```

- **点积：**

  ```python
  vec1 = np.array([1,2,3])
  vec2 = np.array([4,5,6])
  
  dot_product = np.dot(vec1,vec2)
  ```

- **矩阵的转置：**

  ```python
  arr_transposed = arr1.T
  ```

#### 广播（Broadcasting）

广播是 NumPy 中的一种机制，可以在不同形状的数组之间进行运算，自动扩展较小的数组，使其与较大的数组对齐。

- **广播示例：**

  ```python
  arr1 = np.array([1, 2, 3])  # 形状 (3,)
  arr2 = np.array([[4], [5], [6]])  # 形状 (3, 1)
  
  result = arr1 + arr2  # 广播后，arr2 会自动扩展为 (3, 3)
  ```

  结果是：

  ```lua
  [[5 6 7]
   [6 7 8]
   [7 8 9]]
  ```

广播规则：

- 如果数组的维度不同，NumPy 会自动广播小维度数组的形状，使它们匹配。
- 广播时，从最后一维开始，逐维比较。如果维度不同，且其中一个数组的维度为 1，那么可以进行广播扩展。

### **数组的切片、索引、重塑等操作**

#### 切片（Slicing）和索引（Indexing）

- **一维数组切片：**

  ```python
  arr = np.array([1, 2, 3, 4, 5])
  sliced = arr[1:4]  # 提取索引 1 到 3 的元素，结果是 [2, 3, 4]
  ```

- **二维数组切片：**

  ```python
  arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
  sliced_2d = arr_2d[1:, :2]  # 从第二行开始，取前两列arr    行，列
  ```

- **高级索引：** 通过传递一个列表或布尔数组进行索引：

  ```python
  arr = np.array([1, 2, 3, 4, 5])
  indices = np.array([0, 2, 4])
  selected = arr[indices]  # 结果是 [1, 3, 5]
  ```

  或者使用布尔数组：

  ```python
  bool_idx = np.array([True, False, True, False, True])
  selected = arr[bool_idx]  # 结果是 [1, 3, 5]
  ```
  
  ### 举例：`grid = order[..., :2].long()`
  
  - **`order[..., :2]`**：
  
    - `order` 是一个多维张量，`...` 是 Python 中的省略符，表示在该位置保持所有维度的原样。
  
    - `:2` 表示取 `order` 中最后一维的前两个元素。假设 `order` 的形状是 `[batch_size, seq_len, num_features]`，那么 `order[..., :2]` 会选取 `num_features` 中的前两个特征。
  
    - 例如，如果 `order` 的形状是 `[2, 3, 5]`（批量大小为 2，序列长度为 3，每个样本包含 5 个特征），`order[..., :2]` 的形状会变成 `[2, 3, 2]`，也就是取每个样本的前两个特征。
  
    - 假设我们有 2 个样本，每个样本有 3 个时间步，每个时间步有 5 个特征。`order` 张量可能是这样的：
  
      ```python
      order = torch.tensor([[[1, 2, 3, 4, 5],
                             [6, 7, 8, 9, 10],
                             [11, 12, 13, 14, 15]],
                            [[16, 17, 18, 19, 20],
                             [21, 22, 23, 24, 25],
                             [26, 27, 28, 29, 30]]])
      ```
  
    -  `contin = state[..., 2:].float()` 是取从第二列开始的所有数据。
    - 如图是我举了一个例子各种切片方法，是行还是列。
    - ![289d1f9d15edea77c793bf816f3fdbf2](D:\QQ\MessageFile\Tencent Files\2752882718\nt_qq\nt_data\Pic\2024-12\Ori\289d1f9d15edea77c793bf816f3fdbf2.png)

#### 重塑（Reshape）

使用 `reshape` 改变数组的形状，但不改变数据：

```python
arr = np.array([1, 2, 3, 4, 5, 6])
reshaped = arr.reshape((2, 3))  # 2 行 3 列的二维数组
```

- `reshape` 的限制:
  - 新形状的维度数和原形状的元素总数必须匹配。

#### 展开（Flatten）

将多维数组转换为一维数组：

```python
arr = np.array([[1, 2], [3, 4]])
flattened = arr.flatten()  # 结果是 [1, 2, 3, 4]
```

------

###  **随机数生成**

NumPy 提供了强大的随机数生成工具，通过 `np.random` 模块生成各种随机数组和分布。

- **生成随机数组：**

  ```python
  rand_arr = np.random.rand(3, 4)  # 生成 3x4 的均匀分布数组，值在 [0, 1) 之间
  ```

- **生成随机整数：**

  ```python
  rand_int = np.random.randint(0,10,size=(3,3))#生成3*3的随机整数矩阵，范围是0-10
  ```

- **正态分布：**

  ```python
  normal_arr = np.random.randn(3,3)#生3*3的标准正态分布(均值0，方差1)
  ```

- **随机选择元素：**

  ```python
  arr = np.array([1, 2, 3, 4, 5])
  choice = np.random.choice(arr, size=3)  # 从数组中随机选择 3 个元素
  ```
  
  ### 堆叠数组
  
  在 NumPy 中，`np.stack` 函数用于沿指定轴将一系列数组堆叠成一个新的数组。
  
  当你使用 `np.stack(s, axis=0)` 时，你实际上是在将 `s` 中的数组沿着第一个轴（也就是最外层的轴，通常理解为行方向，但在多维数组中可能不完全等同于传统的行和列概念）堆叠起来。
  
  ### 连接数组
  
  `np.concatenate` 是 NumPy 库中的一个函数，用于沿指定轴连接相同形状的两个或多个数组。如果输入数组在某个维度上的形状不匹配，但其他维度上的形状相同，则可以通过指定不同的轴来进行连接。然而，需要注意的是，除了连接轴之外，其他所有维度的大小必须完全相同。
  
  ```python
  numpy.concatenate((a1, a2, ...), axis=0, out=None)
  ```
  
  - `(a1, a2, ...)`：需要连接的数组序列。这个序列可以是一个列表或元组，其中的元素是要连接的数组。
  - `axis`：指定要沿其连接数组的轴。默认值是0，表示沿着第一个轴（行方向，对于二维数组来说）进行连接。如果数组是一维的，那么连接后的数组仍然是一维的。对于二维数组，如果`axis=0`，则数组将按行连接；如果`axis=1`，则数组将按列连接。
  - `out`：此参数是可选的，用于指定存储结果的位置。通常不需要显式指定，因为 NumPy 会自动分配一个新的数组来存储结果。
  
  例子：
  
  ```python
  import numpy as np
  
  a = np.array([[1, 2], [3, 4]])
  b = np.array([[5, 6], [7, 8]])
  
  c_row = np.concatenate((a, b), axis=0)  # 按行连接
  print(c_row)  # 输出:
  # [[1 2]
  #  [3 4]
  #  [5 6]
  #  [7 8]]
  
  c_col = np.concatenate((a, b), axis=1)  # 按列连接
  print(c_col)  # 输出:
  # [[1 2 5 6]
  #  [3 4 7 8]]
  ```

## 第三次学习

### 如何构建一个嵌入层？

1. **网格索引是什么？**
   - 网格索引通常指的是一组离散的类别或者数字。例如，在自然语言处理中，词汇表中的每个单词都会被分配一个唯一的索引（比如单词 "apple" 可能对应索引 5，"banana" 对应索引 7，等等）。这些索引是离散的、整数类型的。
   - 在这个上下文中，“网格索引”可能表示类似于某些位置、类别或标识符的离散值。
2. **什么是“嵌入向量”？**
   - 嵌入向量（Embedding vector）是一个连续的、高维的向量，用来表示每个离散的索引。嵌入向量不是随机的，而是通过训练来学习的，目的是将离散的类别（如单词、ID、位置等）映射到一个固定维度的向量空间，能够捕捉到这些类别之间的关系。
   - 比如，给定某个索引 `i`，嵌入层会返回一个向量 `v_i`，这个向量是一个在高维空间中的点（例如一个 64 维或 128 维的向量），可以捕捉到类别 `i` 的某些特征或意义。
3. **将网格索引映射到嵌入向量：**
   - **映射**：这个过程是通过一个嵌入层（`nn.Embedding`）完成的，嵌入层的作用是把每个离散的整数索引映射到一个对应的向量。例如，索引 `3` 可能会被映射到一个 64 维的向量 `[0.12, -0.34, ..., 0.56]`。
   - **为什么要映射**：神经网络通常不能直接处理离散的类别数据。通过嵌入层，我们把这些离散的索引转换成可以计算的、连续的向量，这样网络可以学习这些类别之间的关系。嵌入空间的维度（如 64 维、128 维）是训练过程中会学习的一个超参数。

**举个例子**：

假设你有一个网格索引集合，包含位置（或者类别）信息：

```python

grid = torch.tensor([0, 1, 2, 3])  # 这是一个包含 4 个索引的张量
```

**创建嵌入层**：

```python
embedding_layer = nn.Embedding(4, 3)  # 将 4 个类别映射到 3 维的嵌入空间   3是嵌入维度
```

- **4**：表示有 4 个不同的类别（比如 0, 1, 2, 3）。
- **3**：表示每个类别将会映射到一个 3 维的向量空间（即每个索引会对应一个 3 维向量）。

**映射过程**：

```python
grid_emb = embedding_layer(grid)
print(grid_emb)
```

输出（可能类似于）：

```python
tensor([[-0.3674,  1.2345,  0.5432],  # 对应索引 0 的嵌入向量
        [ 0.8765, -0.1123,  0.3344],  # 对应索引 1 的嵌入向量
        [ 0.2555,  0.8987, -1.2345],  # 对应索引 2 的嵌入向量
        [ 0.1234, -0.2345,  0.5432]]) # 对应索引 3 的嵌入向量
```

**总结**：

- **"网格索引"** 指的是一些离散的数字（比如类目、位置、ID等），
- **"嵌入向量"** 是这些离散数字的高维连续表示，用一个向量来表示每个离散的类别。
- **"映射"** 就是通过 `nn.Embedding` 层把这些离散的整数索引转换为相应的向量，通常这些向量会通过训练学习到一些有意义的特征，反映出类别之间的相似性或者其他关系。

通过这种方式，神经网络可以有效地处理离散的、类别型的数据，而不需要将它们直接作为整数输入模型。

我遇到的代码示例

```python
#一个嵌入层的初始化
self.grid_embedding = layer_init(nn.Embedding(grid_dim, embedding_dim), std=gain, bias_const=0, init=init) 
#嵌入向量生成
grid_emb = self.tanh(self.grid_embedding(grid))
```









### nn.Linear的用法是什么样的？

`nn.Linear` 的构造函数原型是这样的：

```python
nn.Linear(in_features, out_features, bias=True)
```

**参数**：

- **`in_features`**：输入张量的特征数量（即输入的维度）。它是输入张量的最后一个维度的大小。
- **`out_features`**：输出张量的特征数量（即输出的维度）。
- **`bias`**：是否使用偏置项，默认是 `True`。如果为 `True`，那么输出会有一个额外的偏置项；如果为 `False`，则不使用偏置。

**线性层的数学表示**

给定一个输入张量 `X`（形状为 `[batch_size, in_features]`），线性变换的输出是通过以下公式计算的：

$Y = XW^T + b$

- $X$ 是输入张量。
- $W$ 是权重矩阵，形状为 `[out_features, in_features]`。
- $b$ 是偏置向量，形状为 `[out_features]`。
- $Y$ 是输出张量，形状为 `[batch_size, out_features]`。

`nn.Linear(self.contin_dim, embedding_dim)` **解释**

在你提供的代码中：

```python
self.contin_embedding = layer_init(nn.Linear(self.contin_dim,embedding_dim),std=gain,bias_const=0,init=init)
```

这行代码创建了一个线性层，并将其赋值给 `self.contin_embedding`。它将输入的连续特征 `contin`（维度为 `self.contin_dim`）映射到一个新的维度 `embedding_dim`。

**解释：**

- **`self.contin_dim`**：是输入特征的维度，即每个输入样本中包含的连续特征的数量。例如，如果你有一个包含 10 个连续特征的输入样本，`self.contin_dim` 就是 10。
- **`embedding_dim`**：是输出的特征维度，即这个层将连续特征映射到的维度。假设你将输入的连续特征映射到 64 维的空间，那么 `embedding_dim` 就是 64。

**过程：**

- 输入的张量 `contin`，其形状是 `[batch_size, self.contin_dim]`，表示一个批次中每个样本包含 `self.contin_dim` 个连续特征。
- 通过线性变换，`nn.Linear(self.contin_dim, embedding_dim)` 会将每个样本的 `self.contin_dim` 维特征映射到一个 `embedding_dim` 维的向量。
- 如果 `embedding_dim = 64`，那么线性层的权重矩阵 `W` 的形状是 `[64, self.contin_dim]`，偏置项 `b` 的形状是 `[64]`。

**具体例子**：

假设：

- `self.contin_dim = 10`（输入包含 10 个连续特征）。
- `embedding_dim = 64`（输出映射到 64 维空间）。

代码中的线性层会将每个输入样本的 10 个特征映射到一个 64 维的嵌入向量。输入的张量 `contin` 的形状可能是 `[batch_size, 10]`，输出的张量形状则是 `[batch_size, 64]`。

**例子**：

```python
import torch
import torch.nn as nn

# 假设连续特征的维度是 10，嵌入维度是 64
contin_dim = 10
embedding_dim = 64

# 创建线性层
linear_layer = nn.Linear(contin_dim, embedding_dim)

# 创建一个 batch_size = 2 的输入张量，每个样本有 10 个特征
input_tensor = torch.randn(2, contin_dim)

# 通过线性层进行映射
output_tensor = linear_layer(input_tensor)

print(output_tensor.shape)  # 输出: torch.Size([2, 64])
```

**总结**：

- `nn.Linear(self.contin_dim, embedding_dim)` 是一个全连接层，它会将输入张量中形状为 `[batch_size, self.contin_dim]` 的连续特征映射到一个新的空间，输出张量的形状是 `[batch_size, embedding_dim]`。
- 线性层通过一个权重矩阵和一个偏置向量来进行计算，通常用于特征变换、**降维**、特征融合等任务。
- 在训练过程中，`nn.Linear` 的权重和偏置会通过反向传播自动调整，以适应任务的需求。

### 向量拼接

**举个例子**

假设：

- `grid_emb_0` 和 `grid_emb_1` 形状是 `(2, 3, 4)`，代表每个批次有 3 个位置，每个位置 4 维嵌入。
- `contin_emb` 形状是 `(2, 4)`，表示每个批次的一个 4 维连续特征。

```python
# grid_emb_0 (2, 3, 4)
grid_emb_0 = torch.tensor([[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]],
                           [[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]])

# grid_emb_1 (2, 3, 4)
grid_emb_1 = torch.tensor([[[25, 26, 27, 28], [29, 30, 31, 32], [33, 34, 35, 36]],
                           [[37, 38, 39, 40], [41, 42, 43, 44], [45, 46, 47, 48]]])

# contin_emb (2, 4)
contin_emb = torch.tensor([[50, 51, 52, 53], [54, 55, 56, 57]])

# 拼接
order_emb = torch.cat([grid_emb_0, grid_emb_1, contin_emb.unsqueeze(1).expand(-1, 3, -1)], dim=-1)

print("order_emb:", order_emb)
```

**解释**

- **`contin_emb.unsqueeze(1).expand(-1, 3, -1)`**：
  这里，`contin_emb.unsqueeze(1)` 会将 `contin_emb` 从 `(2, 4)` 转换成 `(2, 1, 4)`，然后通过 `.expand(-1, 3, -1)` 将它扩展到 `(2, 3, 4)`，使它的维度和 `grid_emb_0` 和 `grid_emb_1` 一致。每个批次的连续特征会被复制到每个位置（每个位置都有同样的连续嵌入）。
- **`torch.cat(..., dim=-1)`**：
  在最后一个维度（即嵌入维度）上拼接 `grid_emb_0`、`grid_emb_1` 和扩展后的 `contin_emb`。

**输出**

```python
order_emb: tensor([[[ 1,  2,  3,  4, 25, 26, 27, 28, 50, 51, 52, 53],
                     [ 5,  6,  7,  8, 29, 30, 31, 32, 50, 51, 52, 53],
                     [ 9, 10, 11, 12, 33, 34, 35, 36, 50, 51, 52, 53]],

                    [[13, 14, 15, 16, 37, 38, 39, 40, 54, 55, 56, 57],
                     [17, 18, 19, 20, 41, 42, 43, 44, 54, 55, 56, 57],
                     [21, 22, 23, 24, 45, 46, 47, 48, 54, 55, 56, 57]]])
```

**总结**

- **`torch.cat([...], dim=-1)`**：
  沿着最后一个维度（即嵌入维度）进行拼接。
- **`contin_emb`**：
  `contin_emb` 在最后拼接时，被扩展为每个位置相同的连续嵌入，放在拼接的最后，形成新的 12 维嵌入向量。

拼接后的 `order_emb` 张量的形状是 `(2, 3, 12)`，表示每个批次有 3 个位置，每个位置有 12 维嵌入向量。

我遇到的代码是这样的：

```python
order_emb = torch.cat([grid_emb[..., 0, :], grid_emb[..., 1, :], contin_emb], dim=-1)
```

### 为什么要进行这样的操作？

1. **信息融合：**
   通过 `torch.cat([grid_emb[..., 0, :], grid_emb[..., 1, :], contin_emb], dim=-1)`，将 `grid_emb` 中的第 0 行、第 1 行和 `contin_emb` 结合在一起。这一步的目的是将不同来源的特征信息融合到一个嵌入空间中，为后续的网络层提供更丰富的信息。
2. **非线性变换：**
   `self.tanh(self.order_layer2(order_emb))` 通过使用 `tanh` 激活函数引入非线性变换。非线性变换能够帮助网络更好地捕捉复杂的关系，使得模型有更强的表达能力，而不是仅仅依赖于线性变换。
3. **进一步映射：**
   `self.order_layer3(order_emb)` 通过进一步的线性变换（或其他类型的变换），将融合后的特征映射到最终需要的空间。这一步通常是为了得到最终任务的输出，比如预测、分类或其他任务的结果。

### 如何构造一个RNN网络？

使用GRU（门控循环单元）来实现循环神经网络（RNN）层。

```python
class RNNLayer(nn.Module):
    def __init__(self, input_dim, output_dim, layer_num, init=True):
        super(RNNLayer, self).__init__()
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.layer_num = layer_num
        self.init = init

        self.rnn = nn.GRU(input_dim, output_dim, num_layers=layer_num)
        # self.norm = nn.LayerNorm(outputs_dim)
        if self.init:
            for name, param in self.rnn.named_parameters():
                if 'bias' in name:
                    nn.init.constant_(param, 0)
                elif 'weight' in name:
                    nn.init.orthogonal_(param)

    def forward(self, input, hidden):
        '''
        input: (seq length, batch size, feature dim)
        hidden:(layer num,  batch size, hidden dim)
        output:(seq length, batch size, output dim)
        '''
        output, hidden = self.rnn(input.unsqueeze(0), hidden)
        return output.squeeze(0), hidden
```

其中`nn.GRU` 是 PyTorch 中用于实现门控循环单元（GRU，Gated Recurrent Unit）的类，GRU 是一种常用的循环神经网络（RNN）变体，用于处理序列数据。

`nn.GRU` **构造函数**

```python
torch.nn.GRU(input_size,hidden_size,num_layers=1,bias=True，batch_first=False, dropout=0,bidirectional=False)
```

**参数解释：**

- `input_size`：输入特征的维度，即每个时间步的输入大小（例如，如果输入是词嵌入，`input_size` 是词嵌入的维度）。
- `hidden_size`：隐藏层状态的维度（每个时间步的隐状态大小）。GRU 会输出这个大小的隐状态。
- `num_layers`：GRU 网络的层数，默认值是 1。通常可以设置为多个层以加深网络。
- `bias`：是否使用偏置项，默认值为 `True`。
- `batch_first`：如果为 `True`，则输入和输出的张量的形状将是 `(batch_size, seq_len, input_size)`。如果为 `False`，则形状为 `(seq_len, batch_size, input_size)`。默认值是 `False`。
- `dropout`：在非最后一层之间是否添加 Dropout，默认值为 0（即不使用 Dropout）。
- `bidirectional`：是否使用双向 GRU。双向 GRU 会从正序和逆序两个方向处理输入序列，默认值是 `False`。

**输入**：`input` 是形状为 `(seq_len, batch_size, input_size)` 的张量，表示序列数据。`seq_len` 是序列长度，`batch_size` 是批次大小，`input_size` 是每个时间步的特征数量。如果 `batch_first=True`，输入的形状是 `(batch_size, seq_len, input_size)`。

**输出**：

- `output`：形状为 `(seq_len, batch_size, hidden_size)` 的张量（如果 `batch_first=False`），包含每个时间步的隐藏状态。如果是双向 GRU，则输出会有两个方向的隐藏状态。
- `h_n`：形状为 `(num_layers * num_directions, batch_size, hidden_size)` 的张量，表示最后一个时间步的隐藏状态。`num_directions` 是 2（对于双向 GRU），否则为 1。

**权重初始化**

如果 `init` 参数为 `True`，则对 RNN 的参数进行初始化：

```python
if self.init:
    for name, param in self.rnn.named_parameters():
        if 'bias' in name:
            nn.init.constant_(param, 0)#常量初始化
        elif 'weight' in name:
            nn.init.orthogonal_(param)#正交初始化
            #orthogonal_ 和 constant_ 是 PyTorch 中用于初始化张量（如模型的权重和偏置）的两个函数。

```

- 对 `bias`（偏置项）进行常数初始化，值为 0。
- 对 `weight`（权重矩阵）进行正交初始化。正交初始化有助于防止梯度消失或爆炸问题。

**前向传播**`forward`

```python
def forward(self, input, hidden):
    output, hidden = self.rnn(input.unsqueeze(0), hidden)
    return output.squeeze(0), hidden
```

在前向传播中，`input.unsqueeze(0)` 是在输入的第一个维度（时间步维度）添加一个维度。通常 GRU 接收的输入是 `(seq_len, batch_size, input_dim)`，但有时候需要调整形状来符合 `GRU` 接口要求。然后将输入和隐层状态传递给 `GRU` 层。

### History类

这段代码定义了一个继承自 `nn.Module` 的 PyTorch 神经网络模型，模型的名称是 `history`。它主要包含一个 LSTM 层和一个全连接的线性层，并且使用了额外的输入（`obs`）来进行预测。

```python
class history(nn.Module):
    def __init__(self, input_size=81,obs_size=65,hidden_layer_size=200, output_size=1):
        super().__init__()
        self.hidden_layer_size = hidden_layer_size

        self.lstm = nn.LSTM(input_size, hidden_layer_size,batch_first=True)

        self.linear = nn.Linear(hidden_layer_size*2, output_size)

        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),
                            torch.zeros(1,1,self.hidden_layer_size))
        self.obs=nn.Linear(obs_size, hidden_layer_size)

    def forward(self, input_seq,obs=None):
        input_seq=input_seq.view(-1,144,size_lstm)
        lstm_out, (h,c) = self.lstm(input_seq)
        h = h.squeeze(0)
        if obs==None:
            return h.detach().cpu()
        else:

            h=h.view(-1,grid_num,self.hidden_layer_size)
            obs_=F.relu(self.obs(obs))
            predictions=torch.cat([obs_,h],-1)
            predictions = self.linear(predictions)
            return predictions
```

1. `__init__` **方法**

- 这个初始化方法定义了模型的结构，`input_size` 是输入数据的特征数，`obs_size` 是观察数据的特征数，`hidden_layer_size` 是 LSTM 隐藏层的大小，`output_size` 是输出层的大小。

2. **LSTM** 层

- 创建一个 LSTM 层，输入数据的大小为 `input_size`，输出的隐藏状态维度是 `hidden_layer_size`。`batch_first=True` 表示输入数据的形状是 `(batch_size, seq_len, input_size)`。如果为 `False`，则形状为 `(seq_len, batch_size, input_size)`。默认值是 `False`。

3. **线性层**

- 定义了一个全连接层，将大小为 `hidden_layer_size * 2` 的输入映射到 `output_size`。为什么是 `* 2`？因为后面会将 LSTM 的输出和 `obs` 输入拼接在一起。

4. **初始化隐藏状态**

- 初始化 LSTM 的隐藏状态 `h` 和单元状态 `c`，这里都初始化为全零。
- **隐藏状态和单元状态** 是 LSTM 用来存储当前时间步的“记忆”信息，不是权重。它们在网络的前向传播中不断更新。

6. `forward` **方法**

- 这个方法定义了前向传播的逻辑。

- `input_seq.view(-1, 144, size_lstm)` 重新调整输入序列的形状，`144` 是序列的长度，`size_lstm` 可能是一个预定义的常量，表示每个时间步的输入特征数。

- 然后将输入传入 LSTM 层，得到 `lstm_out`（LSTM 输出的所有时间步的隐状态）和 `(h, c)`（LSTM 的最后一层隐状态和单元状态）。

- `h.squeeze(0)` 去掉多余的维度，使 `h` 的形状为 `(batch_size, hidden_layer_size)`。

7. **处理观察数据**

```python
if obs == None:
    return h.detach().cpu()
else:
    h = h.view(-1, grid_num, self.hidden_layer_size)#h.view() 是 PyTorch 中一个用于 改变张量形状 的函数。它的作用是将一个张量重新调整为指定的形状（即维度）。
    #-1 表示自动推导这个维度的大小，以保证总元素数量不变。
    #grid_num 和 self.hidden_layer_size 是目标形状的其它两个维度。
    obs_ = F.relu(self.obs(obs))#F 是 torch.nn.functional 的别名
    #这个模块包含了很多不需要创建模型参数（如权重或偏置）的函数，例如激活函数、损失函数、卷积操作、池化操作等。
    predictions = torch.cat([obs_, h], -1)
    predictions = self.linear(predictions)
    return predictions
```

- 如果没有提供 `obs` 数据（即 `obs == None`），那么返回 LSTM 的最后一个隐藏状态 `h`，并将其从计算图中分离出来，移到 CPU 上。
- 如果提供了 `obs` 数据：
  1. 将 `h` 重新形状为 `(batch_size, grid_num, hidden_layer_size)`，`grid_num` 是一个预定义的常量，可能是与数据相关的维度。
  2. 使用 ReLU 激活函数处理 `obs` 数据，并将结果传入线性层 `self.obs`。
  3. 使用 `torch.cat` 将处理后的观察数据和 LSTM 的输出拼接成一个新的张量。
  4. 将拼接后的张量传入 `self.linear` 进行最终的预测，并返回预测结果。

**总结**

- 这个模型的输入是一个序列数据（`input_seq`），通过 LSTM 处理后得到隐藏状态。

- 如果提供了额外的观察数据（`obs`），则将其与 LSTM 的输出拼接，然后通过一个线性层进行最终的预测。

- 如果没有提供观察数据，只返回 LSTM 的最后一个隐藏状态。

### 图神经网络自注意力机制（**Graph Attention Network (GAT)** ）

```python
self.attentions = [GraphAttentionLayer(nfeat,nhid,dropout=dropout,alpha=alpha,concat=True,use_dropout=use_dropout) for _in range(nheads)]
```

创建多个自注意力层（`GraphAttentionLayer`），数量是 `nheads`，并将其存储在 `self.attentions` 列表中。每个注意力层的输入特征维度是 `nfeat`，输出特征维度是 `nhid`，并且会使用相同的 `dropout` 和 `alpha` 参数。

这行代码通过列表推导式创建了 `nheads` 个 `GraphAttentionLayer`，并将它们放在了 `self.attentions` 列表中。

```python
for i, attention in enumerate(self.attentions): self.add_module('attention_{}'.format(i), attention)
```

这行代码会将每个注意力层加入到 PyTorch 模型的子模块中。这样做的好处是，PyTorch 能够管理这些子模块（例如自动处理参数和梯度更新）。

`enumerate(self.attentions)`：这个循环遍历 `self.attentions` 列表中的每个 `GraphAttentionLayer`。

`self.add_module('attention_{}'.format(i), attention)`：将每个 `GraphAttentionLayer` 添加为模型的子模块。`'attention_{}'.format(i)` 会为每个注意力头生成一个唯一的名字（例如 `attention_0`, `attention_1`, ...），这些名字会作为模型中子模块的名称。

```python
self.out_att = GraphAttentionLayer(nhid * nheads, output_dim, dropout=dropout, alpha=alpha, concat=False, use_dropout=use_dropout)
```

定义输出层的注意力机制，`out_att` 的输入维度是 `nhid * nheads`，即多个注意力头的输出拼接起来的特征维度，输出维度为 `output_dim`。`concat=False` 表示输出不会再拼接多个注意力头的结果，而是取平均。

`x = torch.cat([att(x, adj) for att in self.attentions], dim=-1)`

对每个注意力头（`self.attentions`）应用自注意力层，并将它们的输出按特征维度拼接起来，得到一个更高维的表示。

#### 什么是多头自注意力机制？

多头自注意力机制（Multi-Head Attention）最早是在 **Transformer** 模型中提出的，Transformer 是一种非常成功的模型架构，广泛应用于自然语言处理（NLP）和其他领域（如图像处理、图神经网络等）。多头自注意力机制是 Transformer 的核心组件之一，但它并不算是一个“新型”网络，而是一个非常有效的 **注意力机制** 的变种。

1. **自注意力机制**（Self-Attention）简介

自注意力机制的核心思想是 **每个元素在序列中与其他元素的关系进行加权**。对于一个给定的输入，模型可以计算每个元素（如词、节点等）与其它元素之间的相关性，并基于这种相关性来调整表示。

2. **什么是多头注意力**？

单个自注意力机制虽然很强大，但它只捕捉到某种特定的关系或信息。为了让模型能够关注到不同的方面，我们可以使用 **多头注意力**，即将输入分成多个子空间，每个子空间都用一个独立的自注意力机制来处理，然后将这些子空间的输出结果合并。

**“多头”** 就是指 **多个注意力头**，每个注意力头可以看作是一个独立的自注意力计算过程，通过多个注意力头，模型能够从不同的角度、不同的子空间捕捉信息。

#### 如何使用多头自注意力机制？

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class GraphAttentionLayer(nn.Module):
    def __init__(self, in_features, out_features, dropout=0.6, alpha=0.2):
        super(GraphAttentionLayer, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.dropout = dropout
        self.alpha = alpha

        # 注意力的学习权重矩阵 W 和系数向量 a
        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))
        self.a = nn.Parameter(torch.zeros(size=(2 * out_features, 1)))  # 用于计算注意力的权重向量

        # 初始化权重
        nn.init.xavier_uniform_(self.W.data, gain=1.0)
        nn.init.xavier_uniform_(self.a.data, gain=1.0)

    def forward(self, h, adj):
        # h: 节点特征，形状 (N, F_in)，N是节点数，F_in是输入特征维度
        # adj: 邻接矩阵，形状 (N, N)，表示图的结构

        # 1. 线性变换：每个节点的特征与权重矩阵 W 相乘
        Wh = torch.mm(h, self.W)  # Wh: 形状为 (N, F_out)

        # 2. 计算注意力系数
        N = Wh.size(0)
        a_input = torch.cat([Wh.repeat(1, N).view(N * N, -1), Wh.repeat(N, 1)], dim=1)
        e = F.leaky_relu(torch.mm(a_input, self.a).view(N, N), negative_slope=self.alpha)

        # 3. 计算注意力权重（通过邻接矩阵进行掩蔽）
        attention = torch.mul(e, adj)  # 相乘确保仅关注连接的节点
        attention = F.softmax(attention, dim=1)

        # 4. 通过注意力权重加权求和邻居节点特征
        h_prime = torch.mm(attention, Wh)

        # 5. 应用dropout
        h_prime = F.dropout(h_prime, self.dropout, training=self.training)

        return h_prime
```

### 演员actor

#### actor_hrl

```python
class actor_hrl(nn.Module):
    def __init__(
        self,
        input_size=40,#输入数据的维度
        hidden_size=32,#隐藏层的维度
        output_size=2,#输出层的维度
        embedding_dim=16,#嵌入层的维度，将每个id映射为16维向量
        id_num=grid_num
    ):
        super(actor_hrl, self).__init__()
        ### LSTM的参数情况
        self.input_size=input_size
        self.hidden_size = hidden_size
        self.output_size=output_size
        self.embedding_dim=embedding_dim
        self.id_embedding = nn.Embedding(
            num_embeddings=id_num, embedding_dim=self.embedding_dim)#这是一层嵌入层，将 ID（比如环境中的某个实体的编号）转换为一个固定维度（embedding_dim）的向量。
        self.layer1 =nn.Linear(self.input_size,self.hidden_size)#这是一个全连接层，将输入的 input_size 维数据映射到 hidden_size 维的隐藏层。
        self.layer2 = nn.Linear(self.embedding_dim*2, 8)#这层是另一个全连接层，将两个嵌入向量（每个嵌入向量的维度embedding_dim，所以总共有 embedding_dim * 2 的输入维度）映射到 8 维。

        self.layer3 = nn.Linear(8, self.output_size)#这是最后一层，将 8 维的向量映射到 output_size 维，即动作的概率分布。
        self.layer_his=nn.Linear(200, self.embedding_dim)#这个层用于处理历史信息，将一个 200 维的输入向量映射到 embedding_dim 维的输出。
    def forward(self,z,his):#
        z=F.elu(self.id_embedding(z))
        his=F.elu(self.layer_his(his))
        z=torch.cat((z,his),-1)
        z = F.elu(self.layer2(z))
        z =self.layer3(z)
        action_prob=F.softmax(z,-1)#将 z 的输出通过 softmax 函数转换为概率分布。softmax 会把输出的值转化为一个概率分布，适用于多类分类问题。
        return action_prob
    
#这个模型的主要作用是根据输入的 ID（z）和历史信息（his），生成一个动作概率分布。它通过多层全连接网络和嵌入层来处理输入数据，最终输出一个动作的概率。这种结构可以应用于强化学习中的策略网络（Actor）。    
```

#### actor

强化学习中的**Actor**网络，通常用于智能体的决策生成。具体来说，这个**Actor**网络是一个神经网络模型，继承自PyTorch的`nn.Module`类，用于根据状态和订单信息生成行动概率。

```python
class Actor(nn.Module):
    def __init__(self, grid_dim, time_dim, embedding_dim, state_contin_dim, order_contin_dim, init=True, use_rnn=False,use_GAT=False, use_neighbor_state=False, merge_method='cat', use_auxi=False, use_dropout=False):
        super(Actor, self).__init__()
        # order : [origin grid id, des grid id, pickup time ,duration, price ]
        self.grid_dim = grid_dim
        self.time_dim = time_dim
        self.embedding_dim = embedding_dim
        self.use_rnn = use_rnn
        self.use_GAT = use_GAT
        self.use_neighbor_state = use_neighbor_state
        self.use_dropout = use_dropout
        self.merge_method = merge_method
        self.use_auxi = use_auxi#控制是否使用辅助网络和是否使用Dropout。
        self.tanh = nn.Tanh()

        self.state_layer = state_embedding(grid_dim, time_dim, embedding_dim, state_contin_dim, init)
        self.order_layer = order_embedding(grid_dim, time_dim, embedding_dim, order_contin_dim, init)
        #用来将状态信息和订单信息转换为嵌入向量的层，通常这两个是通过查找表或嵌入矩阵实现的。
        self.key_embedding_dim = embedding_dim
        self.key_layer = layer_init(nn.Linear(self.key_embedding_dim, embedding_dim), std=1, bias_const=0, init=init)
        #是一个线性层，用于将状态嵌入映射到另一个嵌入空间。
        gain = nn.init.calculate_gain(['tanh', 'relu'][0])
        if self.use_auxi:
            self.auxiliary_layer = layer_init(nn.Linear(self.embedding_dim, embedding_dim), std=gain, bias_const=0,init=init)
#如果use_auxi为True，则定义一个额外的辅助层，用于学习辅助的嵌入。
    def forward(self, state, order, mask, adj=None, hidden_state=None, scale=True, return_logit=False):
        # key embedding
        if mask.dtype is not torch.bool:
            mask = mask.bool()
        state_emb = self.state_layer(state)
        state_emb = self.key_layer(state_emb)
        order_emb = self.order_layer(order)
        compatibility = torch.squeeze(torch.matmul(state_emb[:, None, :], order_emb.transpose(-2, -1)), dim=1)
        #计算的是状态和订单嵌入的相似度，使用了矩阵乘法。通过scale参数对相似度进行缩放，以避免数值不稳定。
        if scale:
            compatibility /= math.sqrt(state_emb.size(-1))
        compatibility[~mask] = -math.inf
        if return_logit:
            return compatibility, hidden_state
        probs = F.softmax(compatibility, dim=-1)
        return probs, hidden_state
#forward方法定义了网络的前向传播过程。它接受state（状态）、order（订单信息）、mask（遮罩，可能用于处理无效位置）等输入。
    def get_state_emb(self, state):
        state_emb = self.state_layer(state)
        return state_emb

    def auxiliary_emb(self, state):
        state_emb = self.state_layer(state)
        auxi_emb = self.tanh(self.auxiliary_layer(state_emb))
        return auxi_emb
#多重遮罩前向传播
    def multi_mask_forward(self, state, order, mask, adj=None, hidden_state=None, scale=True):
        # key embedding
        if mask.dtype is not torch.bool:
            mask = mask.bool()
        state_emb = self.state_layer(state)
        state_emb = self.key_layer(state_emb)
        order_emb = self.order_layer(order)
        # compatibility = torch.matmul(state_emb[:,None,:], order_emb.transpose(-2, -1))
        compatibility = torch.matmul(state_emb[..., None, :], order_emb.transpose(-2, -1))
        if scale:
            compatibility /= math.sqrt(state_emb.size(-1))
        # compatibility= compatibility.repeat(1,mask.shape[1],1)
        repeat_shape = [1 for _ in compatibility.shape]
        repeat_shape[-2] = mask.shape[-2]
        compatibility = compatibility.repeat(tuple(repeat_shape))
        compatibility[~mask] = -math.inf
        probs = F.softmax(compatibility, dim=-1)
        return probs, hidden_state
#得到行动的概率分布，然后将其包装成一个Categorical分布对象，通常用于采样行动。
    def _distribution(self, state, order, mask):
        probs = self.forward(state, order, mask)
        return Categorical(probs=probs)
    #Actor网络主要用于生成行动的概率分布。给定当前的状态和订单信息，网络通过多个嵌入层将其转化为向量表示，然后计算这些表示的兼容性，并通过softmax得到行动概率。该网络还可以支持一些额外的功能，比如使用RNN、图注意力网络、辅助网络等，具体取决于初始化时的设置。
```



### 评论家critic

#### critic_hrl

```python
class critic_hrl(nn.Module):
    def __init__(
            self,
            input_size=40,
            hidden_size=32,
            output_size=6,
            embedding_dim=16,
            id_num=grid_num
    ):
        super(critic_hrl, self).__init__()
        ### LSTM的参数情况
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.embedding_dim = embedding_dim
        self.id_embedding = nn.Embedding(
            num_embeddings=id_num, embedding_dim=self.embedding_dim)
        self.layer1 = nn.Linear(self.input_size, self.hidden_size)
        self.layer2 = nn.Linear(self.embedding_dim * 2, 8)
        self.layer_his = nn.Linear(200, self.embedding_dim)
        self.layer3 = nn.Linear(8, 1)
        self.layer4 = nn.Linear(id_num, 1)
    def forward(self, z,his):
        z = F.elu(self.id_embedding(z))#将 z 输入到嵌入层，然后使用 ELU 激活函数进行非线性变换。
        his = F.elu(self.layer_his(his))#将 his 输入到 layer_his，然后进行 ELU 激活。
        z = torch.cat((z, his), -1)#将 z 和 his 沿着最后一个维度（特征维度）拼接起来。
        z = F.elu(self.layer2(z))#将拼接后的结果输入到 layer2，并使用 ELU 激活。
        z=torch.squeeze(z,-1)#去除多余的维度，通常是在最后一维上的大小为 1 时进行的操作。
        z= F.elu(self.layer3(z))#再次使用 ELU 激活函数。
        z = torch.squeeze(z, -1)#去除多余的维度。
        z = F.elu(self.layer4(z))#最后通过 layer4 层，得到最终输出。返回的 z 是一个标量，表示模型的输出结果。
        return z
    #这个模型似乎是一个强化学习中的“评论员”网络，处理两个输入：z：一个标识符输入，经过嵌入层后表示一个低维嵌入向量。his：历史信息，经过一个全连接层转换为嵌入表示。然后，模型将这两者拼接并通过一系列的全连接层和激活函数，最终输出一个标量值（可能是某个评估或价值）。
```

#### critic

```python
class Critic(nn.Module):
    def __init__(self, grid_dim, time_dim, embedding_dim, state_contin_dim, order_contin_dim, init=True, use_rnn=False,
                 use_GAT=False, use_neighbor_state=False, merge_method='cat', use_auxi=False):
        super(Critic, self).__init__()
        # order : [origin grid id, des grid id, pickup time ,duration, price ]
        self.grid_dim = grid_dim
        self.time_dim = time_dim
        self.embedding_dim = embedding_dim
        self.use_rnn = use_rnn
        self.use_GAT = use_GAT
        self.use_neighbor_state = use_neighbor_state
        self.merge_method = merge_method
        self.use_auxi = use_auxi
        self.tanh = nn.Tanh()

        self.state_layer = state_embedding(grid_dim, time_dim, embedding_dim, state_contin_dim, init)
        # self.order_layer = order_embedding(grid_dim,time_dim,embedding_dim, order_contin_dim)
        self.value_embedding_dim = embedding_dim
        self.value_layer = layer_init(nn.Linear(self.value_embedding_dim, 1), std=1, bias_const=0, init=init)
        gain = nn.init.calculate_gain(['tanh', 'relu'][0])
        if self.use_auxi:
            self.auxiliary_layer = layer_init(nn.Linear(self.embedding_dim, embedding_dim), std=gain, bias_const=0,
                                              init=init)

    def forward(self, state, adj=None, hidden_state=None):
        state_emb = self.state_layer(state)
        value = self.value_layer(state_emb)
        return value, hidden_state

    def get_state_emb(self, state):
        state_emb = self.state_layer(state)
        return state_emb

    def auxiliary_emb(self, state):
        state_emb = self.state_layer(state)
        auxi_emb = self.tanh(self.auxiliary_layer(state_emb))
        return auxi_emb
    #虽然 Critic 和 critic_hrl 都是用于强化学习中的价值网络，但 critic_hrl 更为复杂，加入了 历史信息 和 离散 ID 的嵌入，适用于需要考虑 时间依赖性 或 层次化结构 的任务。Critic 更加简单，通常用于传统的强化学习任务，专注于对当前状态的价值评估。
```

### 马尔科夫决策代理类

```python
#用于解决一个基于时间的决策问题，可能与路径选择、资源分配等相关。
class MdpAgent(object):#马尔科夫决策过程代理类
    def __init__(self, time_len, node_num, gamma=0.99):
        self.gamma = gamma  # discount for future value
        #未来奖励的折扣因子，表示未来奖励的重要程度
        self.time_len = time_len
        #问题的时间长度，表示决策过程中有多少个时间步
        self.node_num = node_num
        self.value_state = np.zeros([time_len + 1, node_num])
        #表示每个节点在每个时间步的状态价值（0-time_len）
        self.n_state = np.zeros([time_len + 1, node_num])
        self.cur_time = 0
        self.value_iter = []#用于保存每次值更新后平均值的列表，方便后续分析。

    def get_value(self, order):
        # [begin node, end node, price, duration ,service type]
        value = order[2] + pow(self.gamma, order[3]) * self.value_state[min(self.cur_time+order[3],self.time_len), order[1]] - self.value_state[self.cur_time, order[0]]
        #pow(self.gamma, order[3])：表示持续时间对未来价值的折扣。
        #self.value_state[min(self.cur_time + order[3], self.time_len), order[1]]：计算操作结束时（经过一段时间后的状态）的节点价值。
        #self.value_state[self.cur_time, order[0]]：当前时间点节点的价值。
        # value= pow(self.gamma,order[3])*self.value_state[min(self.cur_time+order[3],self.time_len), order[1]]  -self.value_state[self.cur_time, order[0]]
        return value

    def update_value(self, order, selected_ids, env):
        value_record = []
        #order：一个表示订单或操作的列表。order 的元素包括起始节点（order[0]），结束节点（order[1]），价格（order[2]），持续时间（order[3]）和服务类型（order[4]）。
        for _node_id in env.get_node_ids():
            num = min(env.nodes[_node_id].idle_driver_num, len(selected_ids[_node_id]))
            for k in range(num):
                id = selected_ids[_node_id][k]
                o = order[_node_id][id]
                # self.n_state[self.cur_time, o[0]] += 1
                value = self.get_value(o)
                td = value
                # self.value_state[self.cur_time,o[0]]+= 1/self.n_state[self.cur_time, o[0]]*td
                self.value_state[self.cur_time, o[0]] = 199 / 200 * self.value_state[self.cur_time, o[0]] + 1 / 200 * td#加权平均更新起始节点状态值
                value_record.append(value)#记录计算的价值
        self.value_iter.append(np.mean(value_record))#每次更新后的平均值

    def save_param(self, dir):
        save_dict = {
            'value': self.value_state,
            'num': self.n_state
        }
        with open(dir + '/' + 'MDP.pkl', 'wb') as f:
            pickle.dump(save_dict, f)

    def load_param(self, dir):
        with open(dir, 'rb') as f:
            MDP_param = pickle.load(f)
        self.value_state = MDP_param['value']
        self.n_state = MDP_param['num']
```

