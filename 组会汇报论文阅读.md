# 论文阅读

## 摘要

不足：然而，现有的方法使用预定义的或自适应的邻接矩阵，其不能准确地反映信号之间的真实世界的关系。

创新：为了解决这个问题，我们提出了一个分解动态图卷积递归网络（DDGCRN）的流量预测。DDGCRN将动态图卷积递归网络与基于RNN的模型相结合，该模型基于时变交通信号生成动态图，允许提取空间和时间特征。此外，DDGCRN将异常信号与正常交通信号分开，并使用数据驱动的方法对其进行建模，以进一步改善预测。我们对六个真实世界数据集的分析结果证明了DDGCRN与当前最先进技术相比的优越性。

## 介绍

近年来，深度学习技术在推动智能交通系统发展方面发挥了巨大作用。自动驾驶的轨迹预测[1]和物体识别[2]、铁路列车调度的强化学习[3]、交通信号控制[4]以及出行需求建模的大数据分析[5][6，7]等领域都从新兴的深度学习应用中受益匪浅。

### 综述

#### 1

第一个问题是如何在不依赖先验知识的情况下动态地捕获道路之间的空间依赖性。在早期的研究中，研究人员使用了一些先验知识（例如，道路段距离、POI相似性）来构建表示空间相关性的图结构。扩散卷积递归神经网络（DCRNN）、时空图卷积网络（STGCN）等是近年来发展起来的具有代表性的神经网络。他们使用路段之间的距离来计算节点相似度，从而构造表示预定义图结构的邻接矩阵。但是，由先验知识构造的邻接矩阵与任务没有直接关系，完全依赖于先验知识和构造方法的合理性，导致邻接矩阵的表达能力有限。

为了解决这一问题，Graph WaveNet、耦合分层卷积递归神经网络（CCRNN）使用自适应邻接矩阵来更好地提取空间特征，并取得了一定的成功，但它们仍然需要预定义的图结构才能达到最佳性能。

自适应图卷积递归网络（AGCRN）和MTGNN在不使用预定义矩阵的情况下，进一步改进了自适应邻接矩阵，并达到了与预定义矩阵相同的效果。然而，预定义矩阵和自适应矩阵都具有它们的权重是静态的缺点。交通状况是一个动态过程，其空间相关性是不断变化的。交通网络以一种既不是预定义的图结构也不是自适应矩阵所能传达的复杂方式随时间变化。

#### 2

第二个问题是如何区分正常信号和异常信号。大多数城市交通网络都是大规模的、非常复杂的、动态的。交通信号自然包含两种信号，即，表示正常交通流的正常信号和表示由于未知原因导致的异常流的异常信号。目前的交通预测方法通常将所有交通信号视为平等的，并且不区分正常和异常交通状况。换句话说，这些方法仅识别和建模存在的时空相关性。

#### 总结

为了解决第一个问题-动态建模的空间依赖性没有先验知识-动态图生成的方法。这里，将对应于交通信号的时间信息与空间嵌入相组合以生成时空嵌入。然后，将动态图嵌入与从交通信号中提取的动态信号相结合以产生动态图。该方法充分考虑了交通信号的周期性和动态性，使得生成的动态图能够捕捉到节点之间最真实的相关性。最后，通过基于RNN的动态图卷积递归模块（DGCRM）提取交通信号的时空相关性。

为了处理区分正常和异常信号的第二个问题，我们使用**残差分解机制**来减去原始信号和反向预测信号，从而隔离任何异常信号。然后可以使用附加DGCRM对这些隔离信号进行建模。通过将各个模块的预测值相加，得到最终的预测结果。考虑到模型在效率和资源占用方面的不足，根据残差分解预测DDGCRN的特点，设计了分段学习的训练策略。在训练的早期阶段，这种策略可以显著减少训练时间和内存消耗，而不会影响性能。

### 本文贡献

- 一种动态图形生成方法。该方法首先根据交通信号中的时间信息生成**时空嵌入**。然后将这些**时空嵌入**与从交通信号中提取的**动态信号**组合以生成**动态图嵌入**，动态图嵌入用于生成动态图。这样，该方法可以生成**动态图结构**，以提取空间特征，而无需任何先验知识。为了提取交通信号的时空特征，我们使用动态图来构建**基于RNN的动态图卷积递归模块**（DGCRM）。
- 一个高效且有效的流量预测框架DDGCRN。 我们的框架区分正常和异常的交通信号，并分别进行建模。 可以通过分析时空嵌入来研究交通状况和时间点之间的关系。
- 一种新颖的训练策略，克服了DDGCRN在效率和资源利用方面的缺点。 这种训练策略减少了训练早期阶段的时间和内存消耗，而不影响模型后续的性能。
- 对六个真实世界数据集的综合分析证实了 DDGCRN 的有效性。 与当前最先进的模型相比，DDGCRN 产生的预测误差显着降低。

## 相关工作

### 交通预测

例如，全连接长短期记忆（FC-LSTM）[32]通过结合 CNN 和 LSTM 对交通数据进行建模。 时空残差网络（ST-ResNet）[14]利用深度残差CNN网络预测城市人群流量，体现了残差网络的强大功能。 然而，上述方法虽然取得了不错的效果，但在基于图的节点数据的场景中效果不佳。

### 时空图神经网络

目前，最先进的流量预测工作主要基于 GCN。 DCRNN [11] 、STGCN [23] 等模型是最具代表性的作品。 这些模型通过预定义的图结构捕获节点之间的空间特征，并使用 CNN 或 RNN 捕获时间特征。 然而，这些模型严重依赖于手动预定义的图结构。 预定义图结构的质量决定了模型预测的预性能。

为了解决这个问题，Graph Wavenet [12]、MTGNN [20] 和 AGCRN [9] 被发明。 这些框架以数据驱动的方式自适应地生成图结构，并因此取得了出色的成果。 最近的研究 STG-NCDE [22] 通过结合自适应图和神经控制微分方程进一步提高了性能。

 一般来说，流量数据包含强且动态的时空相关性。 因此，动态非线性时空相关性建模对于准确的流量预测至关重要。 动态图的动态生成已成为一个新颖的研究方向。 时空图扩散网络（ST-GDN）[33]利用多分辨率流量转换信息和本地-全球区域间依赖性来进行预测。 动态时空感知图神经网络（DSTAGNN）[34]通过直接挖掘历史交通流数据来提取时空相关性，捕获节点之间空间关联的动态属性。 H.彭等人。 [35]提出了一种交通流概率图，并使用强化学习生成动态图以提取时间和空间特征。

## 准备

本节介绍交通网络和交通信号的基本概念以及要解决的预测问题。 它还定义了 GCN 及其空间和时间属性。

**交通网络**，可以表示为图**G=（V，E，A）**，其中V是一组N个节点，代表位于道路网络中相应位置的传感器。 这些传感器负责记录其所在位置的交通信息。 E是一组边，A是从网络中节点之间的成对距离导出的图等。表示为${A}^d∈R_{N\times N}$

**交通信号**，交通信号$x_t∈R_{N\times C}$表示交通网络 G 中所有传感器在时间步 t 的观测值，其中 C 是传感器收集的交通特征。

**交通预测**，设定一个时间窗口 $P$，表示我们会用过去 $P$ 个时间步的数据来进行预测。

定义的历史信号矩阵为：$χ_P = [x_{t−P+1},...,x_{t−1},x_t]∈R^{P×N×C}$

未来交通信号矩阵$γ_Q = [y_{t+1},y_{t−1},..., y_{t+Q}] ∈ R^{Q×N×C}$ .

**GCN（Graph Convolutional Network）**,图卷积操作可以由一阶切比雪夫多项式近似，可以表示为$Z=(I_N+D^{-\frac{1}{2}}AD^{-\frac{1}{2}})XΘ+b$,其中A表示图结构，为半正定矩阵，D是A的度矩阵，$D^{−\frac{1}{2}}AD^{−\frac{1}{2}}$是对A进行归一化，$I_N$是单位矩阵。Θ是一个权重矩阵（通过训练学习），b是一个偏置量，前面括号内的操作实现了对邻接矩阵A进行归一化处理，再加上单位矩阵来保证数值稳定性。X是特征矩阵（即时间步t的交通信号$x_t$），维度为N*C，N是节点数量，C是特征数。

**空间和时间属性**，将空间和时间特性编码为嵌入向量，便于模型在训练过程中学习。

- 交通网络中有 $N$ 个节点。
- 每天传感器采样 $N_d$ 次（表示数据采样的时间频率）。
- 每周有 7 天（用于表示每周的时间模式）,$N_W=7$
- D代表嵌入维度（预先设置）,表示嵌入向量的特征数。

空间特性嵌入矩阵 $E \in \mathbb{R}^{N \times D}$

日内时间嵌入矩阵 $T^D \in \mathbb{R}^{N_d \times D}$

每周时间嵌入矩阵 $T^W \in \mathbb{R}^{N_W \times D}$

嵌入维度的主要作用是将离散的时间、空间特征映射成连续的向量表示，使模型能够更好地捕捉它们之间的关系和相似性。在时间序列或空间数据中，嵌入维度 $D$ 的选择通常会影响模型的表达能力和计算效率：

- **更高的嵌入维度**（即较大的 $D$）可以提供更丰富的表示能力，使模型能够捕捉到更复杂的特征和关系。
- **更低的嵌入维度** 可以减少计算复杂度，防止过拟合，但可能会损失一些细节信息。

## 模型架构

### 动态图生成

1.为了充分考虑道路网络在不同时间点的动态的空间依赖性，本文设计了时空嵌入生成器（STE generator）。

<img src="C:\Users\27528\AppData\Roaming\Typora\typora-user-images\image-20241115182606129.png" alt="image-20241115182606129" style="zoom: 80%;" />

生成器首先找出$χ_P$这P个时间步对应的日嵌入和周嵌入。然后与空间嵌入执行逐元素乘积运算,得到$E^{st}_P$。

2.然后将时间步t的输入信号$x_t$通过MLP层，提取动态信号$F_t$.

<img src="C:\Users\27528\AppData\Roaming\Typora\typora-user-images\image-20241115182701308.png" alt="image-20241115182701308" style="zoom:80%;" />

3.然后生成动态图嵌入：

$E^{st}_t=E^{st}_P⊙F_t$,先通过P个时间步对应的时空嵌入与动态特征$F_t$进行逐元素相乘得到当前时间步的时空嵌入。

将动态信号 $F_t$ 和时间步t的对应时空嵌入$E_t^{st}$ 做元素级乘法，并通过 $⁡tanh$ 激活函数生成动态图嵌入,表示如下：

<img src="C:\Users\27528\AppData\Roaming\Typora\typora-user-images\image-20241115182731084.png" alt="image-20241115182731084" style="zoom:80%;" />

4.接下来进行动态矩阵归一化，为了满足切比雪夫多项式的要求，对动态矩阵进行归一化处理：

<img src="C:\Users\27528\AppData\Roaming\Typora\typora-user-images\image-20241115182809820.png" alt="image-20241115182809820" style="zoom:80%;" />

其中，$A_t^d$ 表示时间步$t$ 的动态图，$D_t$ 是度矩阵，$\text{ReLU}$ 是激活函数，用于去除负值。

5.最后是应用动态卷积公式进一步处理图的特征，以捕捉时空动态关系。表示如下：

<img src="C:\Users\27528\AppData\Roaming\Typora\typora-user-images\image-20241117094336833.png" alt="image-20241117094336833" style="zoom:80%;" />

![](E:\meet\汇报文献\图片\1.png)

![](E:\meet\汇报文献\图片\2.png)

### 节点自适应参数学习

**GCN**通过称为**节点自适应参数学习（NAPL）**的模块进行优化。该模块基于矩阵分解使模型能够学习每个节点的独特流量模式。权重矩阵设置为$θ∈R^{N×C×F}$。其中C是当前输入特征维度，F是输出特征维度。然后，为了优化GCN同时防止过拟合，权重矩阵 $\theta$被分解为三个部分：

- **节点参数矩阵 **$E_g \in R^{N \times d}$：一个节点级的矩阵，用于表示每个节点的特征。
- **两个权重矩阵** $W_g \in R^{d \times C \times F} $和$ b_g \in R^{d \times F}$：其中 $d \leq N$，表示通过降维减少计算复杂度。

分解后，权重矩阵被表示为：$θ=E_gW_g,b=E_gb_g$

优化后的GCN公式为：

<img src="C:\Users\27528\AppData\Roaming\Typora\typora-user-images\image-20241117113719222.png" alt="image-20241117113719222" style="zoom:80%;" />

### 动态图卷积循环模块

基于他人工作，通过动态图卷积方法和NAPL（节点自适应参数学习）模块的组合替换GRU中的矩阵乘积，得到动态图卷积门控循环单元（DGCRU）。 DGCRU 可以表示为：

####  GRU的基本概念

GRU是一种递归神经网络（RNN）的变体，常用于时间序列预测，比如交通、天气等预测任务。GRU的目的是让模型能够“记住”过去的信息，并且有效地过滤掉不重要的信息。它通过“门”机制（如重置门、更新门）来控制信息的流动。

- **更新门 $u_t$**：决定当前时刻的信息需要从多少过去的信息中继承，即记住多少过去的信息。
- **重置门 $r_t$**：决定忽略多少过去的信息。

GRU的输出通常依赖于前一时刻的输出和当前的输入，通过这些“门”的控制，它可以有效地从长序列中提取相关的特征。

#### DGCRU 的基本概念

DGCRU是在**GRU**的基础上改进的版本，与传统的GRU不同，DGCRU使用**动态图卷积**代替了

普通的矩阵运算，同时结合**NAPL（节点自适应参数学习）**的模块，使得它能够处理具有较远

距离空间依赖的情况。

<img src="C:\Users\27528\AppData\Roaming\Typora\typora-user-images\image-20241117114941826.png" alt="image-20241117114941826" style="zoom:80%;" />

公式（8）中的每一个变量代表的含义如下：

- $x_t$ 和 $H_t$ 分别是当前时间步的输入和输出。
- $\sigma$是一个 sigmoid 函数，用于将输出映射到0和1之间。
- $\theta$ 表示动态图的生成，即动态生成不同时间步的空间关系图。
- $W_r, W_u, W_c$ 和 $b_r, b_u, b_c$ 是可学习的参数，用于动态调整每一个时间步的权重

在这个模型中，DGCRU通过这些门结构来提取空间和时间上的相关特征，用于交通信号的时序预测。最终的隐藏状态 $H_t$ 就包含了这些时空特征。

公式一：$r_t=σ(θ[x_t∥H_{t−1},E_t^{st}]EW_r+Eb_r)$,

**$r_t$**：重置门的输出。它控制当前时刻要忽略多少过去的信息。

**$\sigma$**：表示 Sigmoid 函数，将输出值限制在 0 到 1 之间。

**$x_t$**：当前时刻 $t $的输入（例如当前时间步的交通数据）。

**$H_{t-1}$**：前一时刻的隐藏状态，包含过去的信息。

**$E_t^{\text{st}}$**：动态图生成的时空嵌入。

**$\theta$**：动态图生成操作，生成前文提到过的动态图$A_t^d$。

E：参数矩阵，所有公式共用，是节点自适应参数模块设置的节点参数矩阵。

公式二：$u_t=σ(θ[x_t∥H_{t−1},E_t^{st}]EW_u+Eb_u)$,

**$u_t$**：更新门的输出。它控制当前时刻要记住多少过去的信息。

**$\sigma$**：表示 Sigmoid 函数，将输出值限制在 0 到 1 之间。

**$x_t$**：当前时刻 $t $的输入（例如当前时间步的交通数据）。

**$H_{t-1}$**：前一时刻的隐藏状态，包含过去的信息。

**$E_t^{\text{st}}$**：动态图生成的时空嵌入。

**$\theta$**：动态图生成操作，生成前文提到过的动态图$A_t^d$。

公式三：$\hat{h}_t=tanh(θ[x_t∥(r_t⊙H_{t−1}),E_t^{st}]EW_c+Eb_c)$

是候选隐藏状态更新公式。$\hat{h}_t $是 DGCRU 当前时刻的候选隐藏

状态，包含了当前和过去信息的综合。这一步结合了重置门$r_t$的

输出，从而决定了多少过去信息需要被用于生成新的候选状态。

其余变量与前面一致。

公式四：$H_t=u_t⊙H_{t−1}+(1−u_t)⊙\hat{h}_t$,

**$H_t$**：最终的隐藏状态，作为时间步 $t$ 的输出。

**$u_t \odot H_{t-1}$**：前一时刻隐藏状态的一部分，由更新门 $u_t$ 决定保留多少。

**$(1 - u_t) \odot \hat{h}_t$**：候选隐藏状态的一部分，由$1 - u_t$ 控制其加入到最终

隐藏状态中的比例。

DGCRM 是由一系列 DGCRU 依次连接组成的。

每个 DGCRU 都接收两个主要输入：

1. **$X$**：节点的输入特征（例如，交通信号、传感器数据等）。
2. **$E_t^{st}$**：动态图的动态邻接信息（表示不同时间步 $t$ 的空间拓扑结构）。

每个 DGCRU 根据输入数据和上一时刻的隐藏状态，提取时空相关特性。



### 残差分解和多步预测

为了实现多步预测和信号分解，该框架在 DGCRM 之后包括一个由线性层组成的输出子层。 该输出子层有两个输出：

前向预测：$\hat{y}^l=\text{Linear}_{l,f}(H^l)$,$Q\times N\times C$,

反向预测：$x_b^l=\text{Linear}_{l,f}(H^l)$,$P\times N\times C$,

最后的预测结果是各层预测结果相加：$y=∑_n^l\hat{y}^l$

下一层的输入是当前层的$x_p^l$减去反向预测$x_b^l$。模型可以逐步减少与真实值的偏差，从而获得更准确的预测结果，反向预测输出包含了模型在这一层所能捕捉到的信号成分。

通过残差分解（residual decomposition），模型从输入 $x_p^l$中提取出已学习的信息，即通过反向预测输出 $x_b^l$ 将当前层已经学习到的内容分离出来。这样，$x_p^l$中的信息被分解为已学习的部分和未学习的部分。更新后的 $x_p^{l+1}$ 保留了 $x_p^l$ 中尚未被学习到的信息，作为残差传递到下一层。这意味着每一层都会去除已学习的成分，仅将未被捕捉的部分保留给下一层进行建模，从而逐步逼近真实值。

每一层的输出值在最终会相加，形成模型的最终预测。这种逐层相加的方式确保了所有层的贡献都被整合起来，以便形成一个全面的预测结果。

残差分解与多步预测的核心思想是逐步分解输入信号，将未被当前层学习的信息传递到下一层。

这一过程的关键步骤包括：

1. **前向预测（Forecast）：**

   - $\hat{y}^l = Linear_{l,f}(H^l)$：当前层对未来时刻的预测输出，预测结果累加至最终输出。

2. **逆向预测（Backcast）：**

   - $x_b^l = Linear_{l,b}(H^l)$：重建当前层从输入信号 $x_p^l $中学习到的部分。
   - 可以理解为模型从输入中“取走”当前已捕获的信息。

3. **残差更新：**

   - $x_p^{l+1} = x_p^l - x_b^l$：通过残差更新，去除当前层已学习的信息，将剩余的部分（未学习的

     信息）传递到下一层供进一步建模。

4. **多层累加预测：**

   - 各层的预测结果 $\hat{y}^l $累加形成最终输出 $y = \sum_l \hat{y}^l$。

### 分段学习训练策略

受到MTGNN [20]和动态图卷积循环网络（DGCRN）[20]的启发，基于分解模型预测的特征，设计了一种高效且有效的通用训练策略。 该方案称为分段学习。 在训练阶段的早期，仅训练前 L 个块，而不是所有块。 然后，随着训练的继续，逐渐添加更多的块。 因此，模型是逐步训练的，大大减少了训练早期阶段所需的时间和内存。

步骤：

- **输入**：包含训练所需的输入数据，包括交通信号 $X_p$、时间嵌入 

  $T^D$(日嵌入) 和 $T^W$（周嵌入）、节点嵌入 $E$（空间嵌入）、步

  长 $s$（每隔`s`轮增加一次`L`），以及块数 $K$（模型训练中最大允

  许的块数量）。

- **初始化**：设置初始的迭代次数 `epoch` 和块数量 `L`，都为 1。

- **训练循环**：

  - **条件检查**：如果当前的迭代次数 `epoch` 是步长 `s` 的倍数

    （即每隔 `s` 次）且当前块数量 `L` 小于最大块数 `K`，则 `L`

    增加1。

  - **块循环**

    从 1 到 `L`,针对每个块 `l`，执行以下操作：

    - 根据模型中的公式计算预测值$\hat{y}^l$ 和一些中间变量 $x_b^l$。

  - **累计损失**：计算所有块的预测输出 $\hat{y}^l$的累加和 $\hat{γ}_Q$。

  - **损失计算**：根据模型输出 $\hat{γ}_Q$ 和真实值 $γ_Q$ 计算损失函数 $L$。

- **参数更新**：利用损失值 $L$ 进行反向传播，更新模型参数。

- **输出**：最终得到训练好的模型。

## 实验评价

### 数据集

为了评估 DDGCRN 的性能，使用六个真实数据集进行了一系列大规模实验：PeMSD3、PeMSD4、PeMSD7、PeMSD8、PeMS07(M)、PeMS07(L)。 这些数据集包含 Caltrans 绩效测量系统 (PeMS) 每 30 秒收集一次的传感器信息 [38]。 它们在之前的许多研究中已被广泛使用。

### 实验设置

**数据集**按照 `6:2:2` 的比例分为训练集、验证集和测试集。 

**Q、P（信号序列时间步数）**：12。

所有实验均在配备**NVIDIA GeForce GTX 3090**显卡的**Win11**计算机上进行。 

DCGRU中的**隐藏单元数量**：64，**块数量K**：`2`。

**嵌入维度D：**`PEMSD3`为12，`PEMSD4`为10，`PEMSD7`为12，`PEMSD8`

为5 ，`PEMS07(M) `为 8 个，`PEMS07(L) `为 15 个。

**优化器**：Adam 优化器。 **训练epoch**：`100`。

PEMSD7和PEMS07(L)数据集-**批量大小**:`16`，**学习率**:`0.0075`。 

其他数据集-**批量大小**:` 64`，**学习率**:` 0.03`。 

**损失函数**： MAE 

**三个评估指标**：(1) 平均绝对误差 (MAE)、(2) 均方根误差 (RMSE) 和 (3) 平均绝对百分比误差 (MAPE)。

### 基准模型

DDGCRN 的性能与 21 个基线进行比较，包括传统模型和最先进的作品：历史平均模型 (HA) [28] 根据最后 12 个时间步的平均值计算下一个值。

-  ARIMA [39]将自回归与移动平均模型相结合，通过拟合时间序列数据来预测未来。
-  VAR [28]捕获交通序列数据中的相关性。
-  时间卷积网络（TCN）[40]使用因果卷积来建模时间特征。
-  FC-LSTM [32] 通过结合 CNN 和 LSTM 对数据进行建模。 
- GRU-ED[32]是一种简单有效的时间序列预测模型。
-  双自注意力网络（DSANet）[41]使用CNN和双注意力机制进行预测。
-  DCRNN [11] 是基于扩散图卷积的基线，使用 SeqtoSeq 框架进行流量预测。
- STGCN [23] 使用 GCN 和 CNN 捕获时空特征。 
- Graph WaveNet [12]通过使用自适应矩阵来提取隐藏的空间特征。 
- 时空图到序列模型（STG2Seq）[42]使用门控长期和短期编码器来融合长期和短期时间特征。 
- 长短期图卷积网络（LSGCN）[43]结合了新的图注意力网络cosAtt和GCN来准确捕获空间特征，而GLU用于捕获时间特征。
-  时空同步图卷积网络（STSGCN）[44]使用局部时空图卷积来同步捕获时空相关性。
-  时空融合图神经网络（STFGNN）[45]通过多个时空图的融合来捕获时空相关性。 
- 时空图 ODE 网络（STGODE）[46]应用 CGNN（连续图神经网络）来处理 GCN 过平滑问题并提取时空依赖性。
-  AGCRN [9] 通过使用自适应图和 GRU 捕获时空特征。 
- 基于注意力的时空图卷积网络（ASTGCN）[17]将注意力机制与图卷积相结合来对流量数据进行建模。 
- MSTGCN [17] 是 ASTGCN 的变体。
-  图卷积网络 (Z-GCNETs) [21] 的时间 Zigzags 将 zigzag 持久性的概念纳入 GCN 中以提高性能。
-  STG-NCDE [22] 使用两个神经控制微分方程来预测流量。

## 实验结果

### 预测性能比较

 总体而言，我们的模型在 12 个时间步长内实现了最佳精度。 由于传统方法和机器学习模型仅对时间相关性进行建模，并且对数据的平稳性有很强的要求，因此交通数据很难满足这些要求。 根据表 2，很明显这些方法表现出最差的性能。 基于非图的模型，例如TCN和FC-LSTM，使用深度学习方法来捕获交通数据中的时间特征，取得了良好的效果。 然而，这些模型忽略了空间维度的相关性，因此它们的准确性低于基于图的模型，这也证明了为什么对空间相关性进行建模如此重要。

在基于图的模型方面，DCRNN 使用预定义的图结构来捕获空间相关性。 然而，预定义图结构的质量极大地影响模型的最终输出。 AGCRN、STG-NCDE 等模型通过生成自适应矩阵来对空间关系进行建模。 一般来说，他们取得了优异的成绩。 然而，这些模型仍然通过静态图结构来建模空间关系，并没有考虑数据的动态变化。 与其他模型相比，DDGCRN从传感器数据中提取动态信号以构造更合适的邻接矩阵。 结果是更好的预测。

STGODE误差增长速度比其他模型

快得多。 事实上，它的平均误差率

是所有最新模型中最差的。 虽然 

AGCRN 在PEMSD8 数据集上的长期

预测方面的准确性优于 STG-NCDE，

STG-NCDE 的平均效果仍然优于

 AGCRN。最后，DDGCRN 在所有

时间范围内的错误率均明显低于其

他基线，验证了我们模型的卓越性

能。

### 计算成本

我们还比较了 DDGCRN 与 PEMSD4 和 PEMSD8 数据集的其他基线在每个 epoch 的训练时间和推理时间方面的效率。 更具体地说，我们比较了 DDGCRN、AGCRN、STGODE 和 STG-NCDE 在不使用分段学习情况下的速度。对于所有模型，批量大小设置为 64。

如表3所示，DDGCRN和STGODE具有相同的计算成本，仅次于AGCRN。 然而，准确性比其他基线要好得多。 由于其简单的自适应图构建方法，AGCRN 具有最快的计算速度，但由于它不考虑时间点和动态变化，因此其得分不如 STG-NCDE。 STG-NCDE 效果很好，但由于它使用常微分方程 (Odes) 进行建模，因此计算时间相对较长，因此其速度和效率远不如 DDGCRN。

## 消融研究

本文设计了三个不同的模型变体，每个变体移除了模型的某个关键组成

部分，以便观察该部分的贡献：

1. **w/o DG（去掉动态图）**：这个变体去掉了动态图，仅使用节点自适

   应参数学习模块进行建模，目的是测试动态图卷积的作用。

2. **w/o SL（去掉分段学习策略）**：这个变体没有使用分段学习策略训练

   模型，用于测试这种学习策略对模型性能的影响。

3. **w/o NA（去掉节点自适应参数学习模块）**：这个变体去掉了节点自

   适应参数学习模块，仅使用基本的矩阵乘法操作，以测试该模块对模

   型性能的贡献。

实验针对每个变体重复五次，比较了在PEMSD4和PEMSD8数据集上的平均

绝对误差（MAE）、均方根误差（RMSE）和平均绝对百分比误差（MAPE）。

**结果分析**：

- **DDGCRN优于w/o DG**，表明动态图对模型框架的积极作用。
- **w/o SL的表现与DDGCRN相似**，显示分段学习策略有助于减少内存需求和训练时间，同时不影响模型性能。
- **w/o NA的表现不如DDGCRN**，说明节点自适应参数学习模块对模型的整体性能有显著贡献。

总结来说，这些实验说明了动态图、分段学习策略和节点自适应参数学习模块各自在模型性能提升中的重要性。

### 不同类型图结构效果分析

设计了四种变体，每种变体都探索动态图的实用性：

**DDGCRN-dg**：这是具有动态图卷积的 DDGCRN。 

**DDGCRN-ag** ：用 AGCRN 的自适应图替换动态图。

**DDGCRN-c**：使用附加在数据集的处理后的邻接矩

阵作为图卷积的预定义图。 预定义图的连接节点之

间的权重均设置为1，并且是拉普拉斯矩阵归一化。

**DDGCRN-d**：该变量使用节点表示的传感器之间的

距离的倒数作为边的权重。（表示不合理的权重设置）

 毫无疑问，DDGCRN-dg 和 DDGCRN-ag 的性能明显优于使用预定义图的其他变体，证明了人工设计的预定义图在表示交通网络空间相关性方面的局限性。 DDGCRN-dg相对于DDGCRN-ag的优越性能也表明流量条件不是固定的，只能通过考虑网络的动态变化来改进。 此外，DDGCRN-c的性能明显优于DDGCRN-d，这也说明即使图结构相同，不合理的权重设计也会极大地影响图卷积。 这也证明了人工构建图结构的局限性。

### 节点自适应参数学习模块分析

为了测试 NAPL 模块的实用性，设计了三种不同的模块变体：

1. **use NA**：这是使用NAPL模块的DDGCRN模型。
2. **use ND**：这个变体使用节点动态参数学习模块，并将动态图嵌入 $E_t^d$ 替换了节点参数矩阵 $E$ 以实现动态调整。其对应的GCN（图卷积网络）公式为： $Z^t = \left(I_N + D_t^{-\frac{1}{2}} A_t D_t^{-\frac{1}{2}}\right) X E_t^d W_g + E_t^d b_g $
3. **no NA**：这个变体不使用节点自适应参数学习模块，而是使用最简单的线性乘法进行图卷积。

实验在PEMSD4和PEMSD8数据集上进行。为了便于比较，PEMSD4和PEMSD8的批量大小分别设为16和32，学习率分别为0.00075和0.0015。

总体来说，这些设计是为了测试不同节点嵌入策略对模型性能的影响，以验证NAPL模块在图卷积中的实际效果。

表 6 显示了三种变体中每种变体所需的计算时间和 GPU 成本。 从表6可以看出，使用NA和不使用NA之间差距并不大。 然而，使用 ND 的计算时间和 GPU 成本比其他两种变体要大得多。 这是因为节点动态参数学习模块在其过程中会生成一个五维张量，这大大增加了模型的复杂度。 因为这导致资源需求如此之高，不利于模型的实际部署。

不使用 NA 的精度不如使用 NA 或使用 ND 。

 此外，虽然使用 ND 的精度与使用 NA 的精

度相当，但其损失曲线下降缓慢。 使用 NA 以

更低的成本和更快的训练速度达到最佳性能。 

### 时间嵌入

 从这张图中，我们可以提取出以下信息，帮助理解不同时间和不同天数的时空模式差异：

1. **不同时段的流量模式变化**：特定时间点的数据点在空间上有较强的一致性。
2. **工作日与周末的差异**：交通或人流模式在工作日和周末存在差异。这种差异可能与人们的生活习惯、出行需求不同有关。
3. **时空模式的周期性**：嵌入分布的相似性和差异性可以揭示出每天的时间周期。例如，周三、周四在某些时段可能形成相似的簇，表明这些天在该时段具有相似的活动模式。同时，也可以看出整体上某些位置（如左侧或右侧）在特定天数内重复出现，这表明了某些特定模式在每天的相似时间点可能重复出现。
4. **日周期和周周期的相互作用**：图中可以直观展示日周期（每日的嵌入分布）和周周期（工作日和周末的模式差异）。这反映了交通模式受到日周期和周周期的共同影响。例如，DDGCRN-day 变体和 DDGCRN-week 变体分别使用每日和每周嵌入的设计思路，可以通过观察该图来验证这些时间嵌入是否能有效捕捉周期性的流量模式。
5. **热点区域和冷点区域**：从簇的分布密集程度上可以观察到某些区域的点密集，形成热点，这可能是该时段内的活动高峰区域；而分布稀疏的区域则代表活动较少或流量较低的区域。



为了进一步检查不同日期不同时间点交通状况的空间相关性之间的差异，我们可视化 0、6、12 和 18 小时的每日时空嵌入，以及周三、周四、周六的每周嵌入 和周日。 值得注意的是， 在周三和周四，许多嵌入在 0:0 0 和 18:0 0 聚集在一起，表明它们的流量状况相似。 然而，周六和周日却不能这样说。 这里的区别是工作日与周末。 此外，12:00 的嵌入不会与工作日或周末的其他时间点聚集。 这与12:00时的实际交通情况相符，其他时间段较为拥堵，但较为畅通。

**时间嵌入的两种变体**：

- **DDGCRN-day**：移除了“weekly embedding”，

  只使用每日嵌入（daily embedding）来生成

  动态嵌入。

- **DDGCRN-week**：只使用每周嵌入

  （weekly embedding）来生成动态嵌入，

  而不考虑每日嵌入。

## 参数分析

本节分析了两个超参数（块数 K 和嵌入维数 D ）的影响。 通过在 PEMSD4 和 PEMSD8 数据集

上的实验，我们将 `PEMSD4` 上的 K 值从` 1 - 3`，将 D 值从 `4 - 12`，在 `PEMSD8` 上将 D 值

从 `2- 10`。

### 对 K 的敏感性

虽然不带残差分解的单层 DDGCRN 优于最新基线，但结果不如带残差分解的多层 DDGCRN。 这证明分解交通信号是非常有效的。 

### 对 D 的敏感性

只有当 D 位于特定范围内时，模型的性能才是最佳的。这表明嵌入的维度太小，空间和时间信息将难以编码，嵌入维度太大，可能会发生过拟合。

## 结论

**创新**：提出了一种新的用于交通预测的分解动态图模型DDGCRN。该模型利用时空嵌入和交通信号生成动态图。其中一个模块DGCRM捕获时空相关性，而另一个模块DGCRM使用残差分解机制从正常信号中分离异常信号。此外，本文还提出了一种新的训练策略，称为分段学习，以显著减少初始训练所需的时间和资源。

**结果**：在六个数据集上的大量实验中，DDGCRN始终优于其他方法。DDGCRN提出的动态图生成方法性能优异，减少了对先验知识的依赖，进一步增强了时空图的通用性。

**改进之处**：然而，尽管DDGCRN具有优越的性能，但仍有改进的空间。例如，DDGCRN简单地将交通信号分解为正常信号和异常信号进行建模。如果能够对交通信号中的多种交通模式进行分解建模，将会进一步提高模型的性能和可解释性。因此，我们目前的重点是**寻找一种更好的方法来分解交通信号**。

