# 论文阅读

## 摘要

不足：然而，现有的方法使用预定义的或自适应的邻接矩阵，其不能准确地反映信号之间的真实世界的关系。

创新：为了解决这个问题，我们提出了一个分解动态图卷积递归网络（DDGCRN）的流量预测。DDGCRN将动态图卷积递归网络与基于RNN的模型相结合，该模型基于时变交通信号生成动态图，允许提取空间和时间特征。此外，DDGCRN将异常信号与正常交通信号分开，并使用数据驱动的方法对其进行建模，以进一步改善预测。我们对六个真实世界数据集的分析结果证明了DDGCRN与当前最先进技术相比的优越性。

## 介绍

近年来，深度学习技术在推动智能交通系统发展方面发挥了巨大作用。自动驾驶的轨迹预测[1]和物体识别[2]、铁路列车调度的强化学习[3]、交通信号控制[4]以及出行需求建模的大数据分析[5][6，7]等领域都从新兴的深度学习应用中受益匪浅。

### 综述

#### 1

目前有许多用于交通预测的模型[11，21 -23]。例如，图形多注意力网络（GMAN）[24]集成了时间和空间注意力机制。Choi等人设计了时空图神经控制微分方程（STG-NCDE）[22]，它使用神经控制微分方程（NCDE）来捕获交通状况的时空特征。

（MTGNN）由Wu et al. [20]提出，用于挖掘道路段之间的依赖性。然而，尽管这些研究工作做得很好，但有两个关键问题却很少得到解决。第一个问题是如何在不依赖先验知识的情况下动态地捕获道路之间的空间依赖性。在早期的研究中，研究人员使用了一些先验知识（例如，道路段距离、POI相似性）来构建表示空间相关性的图结构。

扩散卷积递归神经网络（DCRNN）[11]、时空图卷积网络（STGCN）[23]等是近年来发展起来的具有代表性的神经网络。他们使用路段之间的距离来计算节点相似度，从而构造表示预定义图结构的邻接矩阵。但是，由先验知识构造的邻接矩阵与任务没有直接关系，完全依赖于先验知识和构造方法的合理性，导致邻接矩阵的表达能力有限。

为了解决这一问题，Graph WaveNet [12]、耦合分层卷积递归神经网络（CCRNN）[6]使用自适应邻接矩阵来更好地提取空间特征，并取得了一定的成功，但它们仍然需要预定义的图结构才能达到最佳性能。

自适应图卷积递归网络（AGCRN）[9]和MTGNN [20]在不使用预定义矩阵的情况下，进一步改进了自适应领矩阵，并达到了与预定义矩阵相同的效果。然而，预定义矩阵和自适应矩阵都具有它们的权重是静态的缺点。交通状况是一个动态过程，其空间相关性是不断变化的。交通网络以一种既不是预定义的图结构也不是自适应矩阵所能传达的复杂方式随时间变化。此外，交通信号灯的不同也会影响预测的效果。

本文目的：本文的研究目的是找出一种不依赖于先验知识的道路相关性动态建模方法。该方法可以缓解应用场景范围的限制，降低建模的复杂度。

#### 2

第二个问题是如何区分正常信号和异常信号。大多数城市交通网络都是大规模的、非常复杂的、动态的。交通信号自然包含两种信号，即，表示正常交通流的正常信号和表示由于未知原因导致的异常流的异常信号。目前的交通预测方法通常将所有交通信号视为平等的，并且不区分正常和异常交通状况。换句话说，这些方法仅识别和建模存在的时空相关性。

#### 总结

为了解决第一个问题-动态建模的空间依赖性没有先验知识-动态图生成的方法。这里，将对应于交通信号的时间信息与空间嵌入相组合以生成时空嵌入。然后，将动态图嵌入与从交通信号中提取的动态信号相结合以产生动态图。该方法充分考虑了交通信号的周期性和动态性，使得生成的动态图能够捕捉到节点之间最真实的相关性。最后，通过基于RNN的动态图卷积递归模块（DGCRM）提取交通信号的时空相关性。

为了处理区分正常和异常信号的第二个问题，我们使用**残差分解机制**来减去原始信号和反向预测信号，从而隔离任何异常信号。然后可以使用附加DGCRM对这些隔离信号进行建模。通过将各个模块的预测值相加，得到最终的预测结果。考虑到模型在效率和资源占用方面的不足，根据残差分解预测DDGCRN的特点，设计了分段学习的训练策略。在训练的早期阶段，这种策略可以显著减少训练时间和内存消耗，而不会影响性能。

### 本文贡献

- 一种动态图形生成方法。该方法首先根据交通信号中的时间信息生成**时空嵌入**。然后将这些**时空嵌入**与从交通信号中提取的**动态信号**组合以生成**动态图嵌入**，动态图嵌入用于生成动态图。这样，该方法可以生成**动态图结构**，以提取空间特征，而无需任何先验知识。为了提取交通信号的时空特征，我们使用动态图来构建**基于RNN的动态图卷积递归模块**（DGCRM）。
- 一个高效且有效的流量预测框架DDGCRN。 我们的框架区分正常和异常的交通信号，并分别进行建模。 可以通过分析时空嵌入来研究交通状况和时间点之间的关系。
- 一种新颖的训练策略，克服了DDGCRN在效率和资源利用方面的缺点。 这种训练策略减少了训练早期阶段的时间和内存消耗，而不影响模型后续的性能。
- 对六个真实世界数据集的综合分析证实了 DDGCRN 的有效性。 与当前最先进的模型相比，DDGCRN 产生的预测误差显着降低。

## 相关工作

### 交通预测

例如，全连接长短期记忆（FC-LSTM）[32]通过结合 CNN 和 LSTM 对交通数据进行建模。 时空残差网络（ST-ResNet）[14]利用深度残差CNN网络预测城市人群流量，体现了残差网络的强大功能。 然而，上述方法虽然取得了不错的效果，但在基于图的节点数据的场景中效果不佳。

### 时空图神经网络

目前，最先进的流量预测工作主要基于 GCN。 DCRNN [11] 、STGCN [23] 等模型是最具代表性的作品。 这些模型通过预定义的图结构捕获节点之间的空间特征，并使用 CNN 或 RNN 捕获时间特征。 然而，这些模型严重依赖于手动预定义的图结构。 预定义图结构的质量决定了模型预测的预性能。

为了解决这个问题，Graph Wavenet [12]、MTGNN [20] 和 AGCRN [9] 被发明。 这些框架以数据驱动的方式自适应地生成图结构，并因此取得了出色的成果。 最近的研究 STG-NCDE [22] 通过结合自适应图和神经控制微分方程进一步提高了性能。

 一般来说，流量数据包含强且动态的时空相关性。 因此，动态非线性时空相关性建模对于准确的流量预测至关重要。 动态图的动态生成已成为一个新颖的研究方向。 时空图扩散网络（ST-GDN）[33]利用多分辨率流量转换信息和本地-全球区域间依赖性来进行预测。 动态时空感知图神经网络（DSTAGNN）[34]通过直接挖掘历史交通流数据来提取时空相关性，捕获节点之间空间关联的动态属性。 H.彭等人。 [35]提出了一种交通流概率图，并使用强化学习生成动态图以提取时间和空间特征。

## 准备

本节介绍交通网络和交通信号的基本概念以及要解决的预测问题。 它还定义了 GCN 及其空间和时间属性。

**交通网络**，可以表示为图**G=（V，E，A）**，其中V是一组N个节点，代表位于道路网络中相应位置的传感器。 这些传感器负责记录其所在位置的交通信息。 E是一组边，A是从网络中节点之间的成对距离导出的图等。表示为${A}^d∈R_{N*N}$

**交通信号**，交通信号$X_t∈R_{N*C}$表示交通网络 G 中所有传感器在时间步 t 的观测值，其中 C 是传感器收集的交通特征。

**交通预测**，设定一个时间窗口 $P$，表示我们会用过去 $P$ 个时间步的数据来进行预测。

定义的历史信号矩阵为：$χP = [x_{t−P+1},...,x_{t−1},x_t]∈R_{P×N×C}$

未来交通信号矩阵$γ_Q = [y_{t+1},y_{t−1},..., y_{t+Q}] ∈ R_{Q×N×C}$ .

**GCN**,图卷积操作可以由一阶切比雪夫多项式近似，$Z=(I_N+D^{-\frac{1}{2}}AD^{-\frac{1}{2}})XΘ+b$,其中A是动态图嵌入，D是度矩阵，$D^{−\frac{1}{2}}AD^{−\frac{1}{2}}$是归一化矩阵，$I_N$是单位矩阵。Θ是一个权重矩阵，b是一个偏移量，前面括号里的操作实现了邻接节点的特征融合。X是特征矩阵，维度为N*C，N是节点数量，C是特征数。

**空间和时间属性**，将空间和时间特性编码为嵌入向量，便于模型在训练过程中学习。

- 交通网络中有 $N$ 个节点（例如传感器位置）。

- 每天传感器采样 $N_d$ 次（表示数据采样的时间频率）。

- 每周有 7 天（用于表示每周的时间模式）。

空间特性嵌入矩阵 $E \in \mathbb{R}^{N \times D}$

日内时间嵌入矩阵 $T^D \in \mathbb{R}^{N_d \times D}$

每周时间嵌入矩阵 $T^W \in \mathbb{R}^{7 \times D}$

交通网络中有 $N = 3 $个节点，表示三个传感器，分别位于城市的三个位置（例如：A、B 和 C 位置）。

每天传感器采样 $N_d = 4$ 次，表示一天内分 4 个时段采集数据（例如：早上、中午、下午、晚上）。

每周 7 天（表示一周的天数：周一到周日）。

嵌入维度 $D = 2$，表示每个特征向量的维度为 2。

## 模型架构

### 动态图生成

1.为了充分考虑道路网络在不同时间点的动态空间依赖性，设计了时空嵌入生成器（STE generator）。生成器首先找出$χP$对应时间的日嵌入和周嵌入。然后与空间嵌入执行逐元素乘积运算。

- 嵌入维度是什么？嵌入维度 $D$是指将时间、空间等高维特征映射到一个较低维空间的维数。在这个模型中，嵌入维度 $D$ 用于表示日嵌入、周嵌入和空间嵌入中每个向量的长度，即每个嵌入向量的特征数。
- 嵌入维度的作用？
- 嵌入维度的主要作用是将离散的时间、空间特征映射成连续的向量表示，使模型能够更好地捕捉它们之间的关系和相似性。在时间序列或空间数据中，嵌入维度 $D$ 的选择通常会影响模型的表达能力和计算效率：
  - **更高的嵌入维度**（即较大的 $D$）可以提供更丰富的表示能力，使模型能够捕捉到更复杂的特征和关系。
  - **更低的嵌入维度** 可以减少计算复杂度，防止过拟合，但可能会损失一些细节信息。

2.然后在时间步t中，当前时间步的输入通过MLP层，以便提取动态信号.

3.然后生成动态图嵌入：

将动态信号 $F_t$ 和时空嵌入$E_t^{st}$ 做元素级乘法，并通过 $⁡\tanh$ 激活函数生成动态图嵌入,使用 $\tanh$ 激活函数可以平滑结果。

4.接下来进行动态矩阵归一化

为了满足切比雪夫多项式的要求，对动态矩阵进行归一化处理：

$D_t^{-\frac{1}{2}} A_t^d D_t^{-\frac{1}{2}} = D_t^{-\frac{1}{2}} \text{ReLU}(E_t^d (E_t^d)^T) D_t^{-\frac{1}{2}}$

其中，$A_t^d$ 表示时间步$t$ 的动态图，$D_t$ 是度矩阵，$\text{ReLU}$ 是激活函数，用于去除负值。

5.最后是动态卷积公式：这里的X是特征矩阵也就是当前时间步t的输入信号$x_t$。

### 节点自适应参数学习

GCN通过称为节点自适应参数学习（NAPL）模块的模块进行优化。基于矩阵分解，该模块使模型能够学习每个节点的独特流量模式。权重矩阵设置为$θ∈R^{N×C×F}$.C其实是当前输入信号的特征数。然后，为了优化GCN同时防止过拟合，将权重矩阵分解为节点参数矩阵$E_g∈R^{N×d}$,F是输出特征

为了优化 GCN 并减少过拟合风险，权重矩阵 $\theta$被分解为三个部分：

- **节点参数矩阵 **$E_g \in R^{N \times d}$：一个节点级的矩阵，用于表示每个节点的特征。
- **两个权重矩阵** $W_g \in R^{d \times C \times F} $和$ b_g \in R^{d \times F}$：用于映射和偏置参数，其中 $d \leq N$，表示通过降维减少计算复杂度。

分解后，权重矩阵被表示为：$θ=E_gW_g,b=E_gb_g$

优化后的GCN公式为：$Z=(I_N+D^{−\frac{1}{2}}AD^{−\frac{1}{2}})XE_gW_g+E_gb_g$.

### 动态图卷积循环模块

基于他人工作，通过动态图卷积方法和NAPL（节点自适应参数学习）模块的组合替换GRU中的矩阵乘积，得到动态图卷积门控循环单元（DGCRU）。 DGCRU 可以表示为：

####  GRU的基本概念

GRU是一种递归神经网络（RNN）的变体，常用于时间序列预测，比如交通、天气等预测任务。GRU的目的是让模型能够“记住”过去的信息，并且有效地过滤掉不重要的信息。它通过“门”机制（如重置门、更新门）来控制信息的流动。

- **更新门 $u_t$**：决定当前时刻的信息需要从多少过去的信息中继承，即记住多少过去的信息。
- **重置门 $r_t$**：决定忽略多少过去的信息。

GRU的输出通常依赖于前一时刻的输出和当前的输入，通过这些“门”的控制，它可以有效地从长序列中提取相关的特征。

#### DGCRU 的基本概念

DGCRU是在GRU的基础上改进的版本，专门用于提取交通信号的时空特征。与传统的GRU不同，DGCRU使用动态图卷积代替了普通的矩阵运算，以更好地捕捉不同位置（例如道路、路口）之间的空间关系。同时，DGCRU结合了一个称为NAPL（Non-Adjacency Point Layer，非邻接点层）的模块，使得它能够处理具有较远距离空间依赖的情况。

公式（8）中的每一个变量代表的含义如下：

- $x_t$ 和 $H_t$ 分别是当前时间步的输入和输出。
- $\sigma$是一个 sigmoid 函数，用于将输出映射到0和1之间。
- $\theta$ 表示动态图的生成，即动态生成不同时间步的空间关系图。
- $W_r, W_u, W_c$ 和 $b_r, b_u, b_c$ 是可学习的参数，用于动态调整每一个时间步的权重

在这个模型中，DGCRU通过这些门结构来提取空间和时间上的相关特征，用于交通信号的时序预测。最终的隐藏状态 $H_t$ 就包含了这些时空特征。

公式一：$r_t=σ(θ[x_t∥H_{t−1},E_t^{st}]EW_r+Eb_r)$,

**$r_t$**：重置门的输出。它控制当前时刻要忽略多少过去的信息。

**$\sigma$**：表示 Sigmoid 函数，将输出值限制在 0 到 1 之间。

**$x_t$**：当前时刻 $t $的输入（例如当前时间步的交通数据）。

**$H_{t-1}$**：前一时刻$t-1$ 的隐藏状态，包含过去的信息。

**$E_t^{\text{st}}$**：动态图生成的空间特征，表示当前时刻的图结构。

**$\theta$**：动态图生成操作，生成包含当前时刻时空相关性的特征。

**$W_r 和 b_r$**：可学习的权重矩阵和偏置，用于计算重置门的输出。

公式二：$u_t=σ(θ[x_t∥H_{t−1},E_t^{st}]EW_u+Eb_u)$,更新门。

公式三：$\hat{h}_t=tanh(θ[x_t∥(r_t⊙H_{t−1}),E_t^{st}]EW_c+Eb_c)$,候选隐藏状态 

$\hat{h}_t $是 DGCRU 当前时刻的临时状态，包含了当前和过去信息的综合。这一步结合了重置门的输出，从而决定了多少过去信息需要被用于生成新的候选状态。

公式四：$H_t=u_t⊙H_{t−1}+(1−u_t)⊙\hat{h}_t$,

**$H_t$**：最终的隐藏状态，作为时间步 $t$ 的输出。

**$u_t \odot H_{t-1}$**：前一时刻隐藏状态的一部分，由更新门 $u_t$ 决定保留多少。

**$(1 - u_t) \odot \hat{h}_t$**：候选隐藏状态的一部分，由$1 - u_t$ 控制其加入到最终隐藏状态中的比例。

E是一个参数矩阵。

### 残差分解和多步预测

为了实现多步预测和信号分解，该框架在 DGCRM 之后包括一个由线性层组成的输出子层。 该输出子层有两个输出：

前向预测：$\hat{y}^l=\text{Linear}_{l,f}(H^l)$,$Q\times N\times C$,

反向预测：$x_b^l=\text{Linear}_{l,f}(H^l)$,$P\times N\times C$,

最后的预测结果是各层预测结果相加：$y=∑_n^l\hat{y}^l$

下一层的输入是当前层的$x_p^l$减去反向预测$x_b^l$。模型可以逐步减少与真实值的偏差，从而获得更准确的预测结果，反向预测输出包含了模型在这一层所能捕捉到的信号成分。

通过残差分解（residual decomposition），模型从输入 $x_p^l$中提取出已学习的信息，即通过反向预测输出 $x_b^l$ 将当前层已经学习到的内容分离出来。这样，$x_p^l$中的信息被分解为已学习的部分和未学习的部分。更新后的 $x_p^{l+1}$ 保留了 $x_p^l$ 中尚未被学习到的信息，作为残差传递到下一层。这意味着每一层都会去除已学习的成分，仅将未被捕捉的部分保留给下一层进行建模，从而逐步逼近真实值。

每一层的输出值在最终会相加，形成模型的最终预测。这种逐层相加的方式确保了所有层的贡献都被整合起来，以便形成一个全面的预测结果。

### 分段学习训练策略

受到MTGNN [20]和动态图卷积循环网络（DGCRN）[20]的启发，基于分解模型预测的特征，设计了一种高效且有效的通用训练策略。 该方案称为分段学习。 在训练阶段的早期，仅训练前 L 个块，而不是所有块。 然后，随着训练的继续，逐渐添加更多的块。 因此，模型是逐步训练的，大大减少了训练早期阶段所需的时间和内存。

步骤：

- **输入**：包含训练所需的输入数据，包括交通信号 $X_p$、时间嵌入 $T^D$(日嵌入) 和 $T^W$（周嵌入）、节点嵌入 $E$（空间嵌入）、步长 $s$（每隔`s`轮增加一次`L`），以及块数 $K$（模型训练中最大允许的块数量）。

- **初始化**：设置初始的迭代次数 `epoch` 和块数量 `L`，都为 1。

- **训练循环**：

  - **条件检查**：如果当前的迭代次数 `epoch` 是步长 `s` 的倍数（即每隔 `s` 次）且当前块数量 `L` 小于最大块数 `K`，则 `L`增加1。

  - **块循环**

    从 1 到 `L`,针对每个块 `l`，执行以下操作：

    - 根据模型中的公式 (Eq.9 和 Eq.10) 计算预测值$\hat{y}^l$ 和一些中间变量 $x_b^l$。

  - **累计损失**：计算所有块的预测输出 $\hat{y}^l$的累加和 $\hat{y}_Q$。

  - **损失计算**：根据模型输出 $\hat{y}_Q$ 和真实值 $y_Q$ 计算损失函数 $L$。

- **参数更新**：利用损失值 $L$ 进行反向传播，更新模型参数。

- **迭代更新**：增加迭代次数 `epoch`，直到模型收敛。

- **输出**：最终得到训练好的模型。

## 实验评价

### 数据集

为了评估 DDGCRN 的性能，使用六个真实数据集进行了一系列大规模实验：PeMSD3、PeMSD4、PeMSD7、PeMSD8、PeMS07(M)、PeMS07(L)。 这些数据集包含 Caltrans 绩效测量系统 (PeMS) 每 30 秒收集一次的传感器信息 [38]。 它们在之前的许多研究中已被广泛使用。

### 实验设置

数据集按照 6:2:2 的比例分为训练集、验证集和测试集，下一小时的交通状况预测基于前一小时观察到的状况。 具体地，Q设置为12，P设置为12。所有实验均在配备NVIDIA GeForce GTX 3090显卡的Win11计算机上进行。 关于超参数，DCGRU中的隐藏单元数量设置为64，块数量K设置为2。嵌入维度D设置如下：PEMSD3为12，PEMSD4为10，PEMSD7为12，PEMSD8为5 ，PEMS07(M) 为 8 个，PEMS07(L) 为 15 个。

该模型使用 Adam 优化器进行训练。 训练epoch设置为100。对于PEMSD7和PEMS07(L)数据集，由于图卷积操作使用大量内存，批量大小设置为16，学习率设置为0.0075。 对于其他数据集，批量大小设置为 64，学习率为 0.03。 使用 MAE 作为损失函数来训练模型。为了评估性能，使用了三个评估指标：(1) 平均绝对误差 (MAE)、(2) 均方根误差 (RMSE) 和 (3) 平均绝对百分比误差 (MAPE)。

### 基准模型

DDGCRN 的性能与 21 个基线进行比较，包括传统模型和最先进的作品：历史平均模型 (HA) [28] 根据最后 12 个时间步的平均值计算下一个值。

-  ARIMA [39]将自回归与移动平均模型相结合，通过拟合时间序列数据来预测未来。
-  VAR [28]捕获交通序列数据中的相关性。
-  时间卷积网络（TCN）[40]使用因果卷积来建模时间特征。
-  FC-LSTM [32] 通过结合 CNN 和 LSTM 对数据进行建模。 
- GRU-ED[32]是一种简单有效的时间序列预测模型。
-  双自注意力网络（DSANet）[41]使用CNN和双注意力机制进行预测。
-  DCRNN [11] 是基于扩散图卷积的基线，使用 SeqtoSeq 框架进行流量预测。
- STGCN [23] 使用 GCN 和 CNN 捕获时空特征。 
- Graph WaveNet [12]通过使用自适应矩阵来提取隐藏的空间特征。 
- 时空图到序列模型（STG2Seq）[42]使用门控长期和短期编码器来融合长期和短期时间特征。 
- 长短期图卷积网络（LSGCN）[43]结合了新的图注意力网络cosAtt和GCN来准确捕获空间特征，而GLU用于捕获时间特征。
-  时空同步图卷积网络（STSGCN）[44]使用局部时空图卷积来同步捕获时空相关性。
-  时空融合图神经网络（STFGNN）[45]通过多个时空图的融合来捕获时空相关性。 
- 时空图 ODE 网络（STGODE）[46]应用 CGNN（连续图神经网络）来处理 GCN 过平滑问题并提取时空依赖性。
-  AGCRN [9] 通过使用自适应图和 GRU 捕获时空特征。 
- 基于注意力的时空图卷积网络（ASTGCN）[17]将注意力机制与图卷积相结合来对流量数据进行建模。 
- MSTGCN [17] 是 ASTGCN 的变体。
-  图卷积网络 (Z-GCNETs) [21] 的时间 Zigzags 将 zigzag 持久性的概念纳入 GCN 中以提高性能。
-  STG-NCDE [22] 使用两个神经控制微分方程来预测流量。

## 实验结果

### 预测性能比较

表 2 基于六个数据集比较了每个模型的性能。 总体而言，我们的模型在 12 个时间步长内实现了最佳精度。 由于传统方法和机器学习模型仅对时间相关性进行建模，并且对数据的平稳性有很强的要求，因此交通数据很难满足这些要求。 根据表 2，很明显这些方法表现出最差的性能。 基于非图的模型，例如TCN和FC-LSTM，使用深度学习方法来捕获交通数据中的时间特征，取得了良好的效果。 然而，这些模型忽略了空间维度的相关性，因此它们的准确性低于基于图的模型，这也证明了为什么对空间相关性进行建模如此重要。

在基于图的模型方面，DCRNN 使用预定义的图结构来捕获空间相关性。 然而，预定义图结构的质量极大地影响模型的最终输出。 AGCRN、STG-NCDE 等模型通过生成自适应矩阵来对空间关系进行建模。 一般来说，他们取得了优异的成绩。 然而，这些模型仍然通过静态图结构来建模空间关系，并没有考虑数据的动态变化。 与其他模型相比，DDGCRN从传感器数据中提取动态信号以构造更合适的邻接矩阵。 结果是更好的预测。

使用 PEMSD4 和 PEMSD8 数据集对每个步骤的预测误差指标进行可视化，以便于更好地将 DDGCRN 与其他基线进行比较。 如图2所示，虽然STGODE在超短期预测方面表现良好，但其单步误差增长速度比其他模型快得多。 事实上，它的平均错误率是所有最新模型中最差的。 虽然 AGCRN 在PEMSD8 数据集上的长期预测方面的准确性优于 STG-NCDE，STG-NCDE 的平均效果仍然优于 AGCRN。最后，DDGCRN 在所有时间范围内的错误率均明显低于其他基线，验证了我们模型的卓越性能。

### 计算成本

我们还比较了 DDGCRN 与 PEMSD4 和 PEMSD8 数据集的其他基线在每个 epoch 的训练时间和推理时间方面的效率。 更具体地说，我们比较了 DDGCRN、AGCRN、STFODE 和 STG-NCDE 在不使用分段学习情况下的速度。对于所有模型，批量大小设置为 64。

如表3所示，DDGCRN和STGODE具有相同的计算成本，仅次于AGCRN。 然而，准确性比其他基线要好得多。 由于其简单的自适应图构建方法，AGCRN 具有最快的计算速度，但由于它不考虑时间点和动态变化，因此其得分不如 STG-NCDE。 STG-NCDE 效果很好，但由于它使用常微分方程 (Odes) 进行建模，因此计算时间相对较长，因此其速度和效率远不如 DDGCRN。

## 消融研究

本节旨在通过一系列实验来证明我们模型的关键组件和课程学习的有效性。 以下变体旨在验证不同模型组合的效果：

这部分内容是关于一个模型的实验设计和结果分析，用来验证不同模块在模型性能上的作用。它主要涉及三个不同的模型变体，每个变体移除了模型的某个关键组成部分，以便观察该部分的贡献：

1. **w/o DG（去掉动态图）**：这个变体去掉了动态图，仅使用节点自适应参数学习模块进行建模，目的是测试动态图卷积的作用。
2. **w/o SL（去掉分段学习策略）**：这个变体没有使用分段学习策略训练模型，用于测试这种学习策略对模型性能的影响。
3. **w/o NA（去掉节点自适应参数学习模块）**：这个变体去掉了节点自适应参数学习模块，仅使用基本的矩阵乘法操作，以测试该模块对模型性能的贡献。

实验针对每个变体重复五次，比较了在PEMSD4和PEMSD8数据集上的平均绝对误差（MAE）、均方根误差（RMSE）和平均绝对百分比误差（MAPE）。

**结果分析**：

- **DDGCRN优于w/o DG**，表明动态图对模型框架的积极作用。
- **w/o SL的表现与DDGCRN相似**，显示分段学习策略有助于减少内存需求和训练时间，同时不影响模型性能。
- **w/o NA的表现不如DDGCRN**，说明节点自适应参数学习模块对模型的整体性能有显著贡献。

总结来说，这些实验说明了动态图、分段学习策略和节点自适应参数学习模块各自在模型性能提升中的重要性。

### 不同类型图结构效果分析

本小节的目的是分析不同图结构对模型性能的影响。 为此，设计了四种变体，每种变体都探索动态图的实用性：

DDGCRN-dg：这是具有动态图卷积的 DDGCRN。 

DDGCRN-ag ：用 AGCRN 的自适应图替换动态图。

 DDGCRN-c：使用附加到数据集的处理后的邻接矩阵作为图卷积的预定义图。 预定义图的连接节点之间的权重均设置为1，并且是拉普拉斯矩阵归一化。

DDGCRN-d：该变量使用节点表示的传感器之间的距离的倒数作为边的权重。

四种变体的结果如表5所示。 毫无疑问，DDGCRN-dg 和 DDGCRN-ag 的性能明显优于使用预定义图的其他变体，证明了人工设计的预定义图在表示交通网络空间相关性方面的局限性。 DDGCRN-dg相对于DDGCRN-ag的优越性能也表明流量条件不是固定的，只能通过考虑网络的动态变化来改进。 此外，DDGCRN-c的性能明显优于DDGCRN-d，这也说明即使图结构相同，不合理的权重设计也会极大地影响图卷积。 这也证明了人工构建图结构的局限性。

### 节点自适应参数学习模块分析

为了测试 NAPL 模块的实用性，设计了三种不同的模块变体：

这部分内容介绍了测试NAPL（节点自适应参数学习）模块的可行性设计的三种模型变体：

1. **use NA**：这是使用NAPL模块的DDGCRN模型。
2. **use ND**：这个变体使用节点动态参数学习模块，并将动态图嵌入 EtdE_t^dEtd 替换了节点嵌入 EEE 以实现动态调整。其对应的GCN（图卷积网络）公式为： Zt=(IN+Dt−12AtDt−12)XEtdWg+EtdbgZ^t = \left(I_N + D_t^{-\frac{1}{2}} A_t D_t^{-\frac{1}{2}}\right) X E_t^d W_g + E_t^d b_gZt=(IN+Dt−21AtDt−21)XEtdWg+Etdbg 其中，这个模块通过将动态参数学习模块中的节点嵌入替换为动态图嵌入，从而实现动态调整。
3. **no NA**：这个变体不使用节点自适应参数学习模块，而是使用最简单的线性乘法进行图卷积。

实验在PEMSD4和PEMSD8数据集上进行。为了便于比较，PEMSD4和PEMSD8的批量大小分别设为16和32，学习率分别为0.00075和0.0015。

总体来说，这些设计是为了测试不同节点嵌入策略对模型性能的影响，以验证NAPL模块在图卷积中的实际效果。

表 6 显示了三种变体中每种变体所需的计算时间和 GPU 成本。 从表6可以看出，使用NA和不使用NA之间差距并不大。 然而，使用 ND 的计算时间和 GPU 成本比其他两种变体要大得多。 这是因为节点动态参数学习模块在其过程中会生成一个五维张量，这大大增加了模型的复杂度。 因为这导致资源需求如此之高，不利于模型的实际部署。

图3比较了PEMSD4和PEMSD8数据集测试集的测试损失曲线。 虽然早期损失曲线下降很快，但不使用 NA 的精度不如使用 NA 或使用 ND 。 此外，虽然使用 ND 的精度与使用 NA 的精度相当，但其损失曲线下降缓慢。 事实上，使用 ND 需要比使用 NA 多两倍的 epoch 才能达到其峰值精度。 此外，使用 ND 的每个时期的训练时间是使用 NA 的两倍多。 结果是，使用 ND 通过训练达到与使用 NA 相同的性能水平需要三到四倍的时间。 这不符合成本效益。 总体而言，与其他两种变体相比，使用 NA 以更低的成本和更快的训练速度达到最佳性能。 由于这个原因，选择 NAPL 模块来优化 GCN。

### 时间嵌入

为了验证使用两种不同时间嵌入（每天和每周）的有效性，为下一组消融实验准备了两个 DDGCRN 变体。

DDGCRN-day：此变体删除了每周嵌入，仅使用每日嵌入来生成动态嵌入。 DDGCRN-week：此变体仅使用每周嵌入来生成动态嵌入。 使用 PEMSD4 和 PEMSD8 数据集进行实验，并报告所有指标的平均值。 图 4 说明了结果。 总之，两种时间嵌入都是有效的。 具体而言，短期内 DDGCRN-day 似乎优于 DDGCRN，但总体而言不如 DDGCRN。 现实世界的交通信号通常包含每日和每周的周期性，这反映在两种嵌入对最终结果的贡献中。
